{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIDevs2 tasks from newest at the top to oldest at the bottom ,updated daily, to be cleaned ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from utilities.config import AI_DEVS_SERVER, AI_DEVS_API_KEY, OPEN_AI_API_KEY\n",
    "import openai\n",
    "\n",
    "\n",
    "# by działało, uzupelnij plik .env w /utilities\n",
    "BASE_URL = AI_DEVS_SERVER\n",
    "API_KEY = AI_DEVS_API_KEY\n",
    "openai.api_key  = OPEN_AI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#!pip install --upgrade openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token(task_name):\n",
    "    url = f\"{BASE_URL}/token/{task_name}\"\n",
    "    payload = {\n",
    "        \"apikey\": API_KEY\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # Return the entire JSON response\n",
    "    else:\n",
    "        print(f\"Error getting token: {response.text}\")\n",
    "        return None\n",
    "\n",
    "def get_task(token):\n",
    "    url = f\"{BASE_URL}/task/{token}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # Return the entire JSON response\n",
    "    else:\n",
    "        print(f\"Error getting task: {response.text}\")\n",
    "        return None\n",
    "\n",
    "def submit_answer(token, answer):\n",
    "    url = f\"{BASE_URL}/answer/{token}\"\n",
    "    payload = {\n",
    "        \"answer\": answer\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    return response.json()  # Return the entire JSON response\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-4\", max_tokens=300, temperature=0.3): # or model=\"gpt-3.5-turbo\"\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "        return response.choices[0].message[\"content\"]\n",
    "    except openai.error.OpenAIError as e:\n",
    "        print(f\"OpenAI error: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# liar\n",
    "\n",
    "Jest to mechanizm, który mówi nie na temat w 1/3 przypadków. Twoje zadanie polega na tym, aby do endpointa /task/ wysłać swoje pytanie w języku angielskim (dowolne, np “What is capital of Poland?’) w polu o nazwie ‘question’ (metoda POST, jako zwykłe pole formularza, NIE JSON). System API odpowie na to pytanie (w polu ‘answer’) lub zacznie opowiadać o czymś zupełnie innym, zmieniając temat. Twoim zadaniem jest napisanie systemu filtrującego (Guardrails), który określi (YES/NO), czy odpowiedź jest na temat. Następnie swój werdykt zwróć do systemu sprawdzającego jako pojedyncze słowo YES/NO. Jeśli pobierzesz treść zadania przez API bez wysyłania żadnych dodatkowych parametrów, otrzymasz komplet podpowiedzi. Skąd wiedzieć, czy odpowiedź jest ‘na temat’? Jeśli Twoje pytanie dotyczyło stolicy Polski, a w odpowiedzi otrzymasz spis zabytków w Rzymie, to odpowiedź, którą należy wysłać do API to NO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"liar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(token, question):\n",
    "    url = f\"{BASE_URL}/task/{token}\"\n",
    "    payload = {\n",
    "        \"question\": question\n",
    "    }\n",
    "    response = requests.post(url, data=payload)  # Using data instead of json\n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # Return the entire JSON response\n",
    "    else:\n",
    "        print(f\"Error asking question: {response.text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is your favorite type of cheese?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question = \"What the moon?\"\n",
    "question = get_completion(\"respond with random question\", model=\"gpt-3.5-turbo\", max_tokens=100, temperature=0.8)\n",
    "\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your favorite type of cheese? : \"Jurassic Park\" was the highest-grossing film ever at the time of its release in 1993.\n"
     ]
    }
   ],
   "source": [
    "token = get_token(task_name)['token']\n",
    "\n",
    "answer_to_question = ask_question(token, question)['answer']\n",
    "\n",
    "print(question + \" : \" + answer_to_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NO'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Given the question '{question}' and the answer '{answer_to_question}', is the answer relevant? Respond with YES or NO.\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt, model=\"gpt-3.5-turbo\", max_tokens=100, temperature=0.2)\n",
    "\n",
    "response.strip()  # Stripping to ensure there's no extra whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_answer(token, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# blogger\n",
    "\n",
    "Napisz wpis na bloga (w języku polskim) na temat przyrządzania pizzy Margherity. Zadanie w API nazywa się ”blogger”. Jako wejście otrzymasz spis 4 rozdziałów, które muszą pojawić się we wpisie. Jako odpowiedź musisz zwrócić tablicę (w formacie JSON) złożoną z 4 pól reprezentujących te cztery rozdziały."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"blogger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wstęp: kilka słów na temat historii pizzy', 'Niezbędne składniki na pizzę', 'Robienie pizzy', 'Pieczenie pizzy w piekarniku']\n"
     ]
    }
   ],
   "source": [
    "token = get_token(task_name)['token']\n",
    "task = get_task(token)['blog']\n",
    "\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing a Blog Post - Best Solution - in One Prompt and Dividing Afterward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wstęp: kilka słów na temat historii pizzy\\n\\nPizza jest jednym z najbardziej znanych i uwielbianych dań na całym świecie. Jej historia sięga starożytności, a dokładniej do starożytnego Rzymu. Początkowo była to prosta płaska bułka, którą podawano z różnymi dodatkami. Jednak to we Włoszech pizza zyskała swoją popularność i stała się symbolem tego kraju. Dziś pizza jest dostępna w wielu różnych wariantach, ale jednym z najbardziej klasycznych i uwielbianych jest Margherita.', 'Niezbędne składniki na pizzę\\n\\nAby przygotować pyszną Margheritę, potrzebujemy kilku podstawowych składników. Przede wszystkim musimy mieć dobrej jakości mąkę, najlepiej typu 00, która jest najbardziej odpowiednia do pizzy. Potrzebujemy również drożdży, które dodamy do mąki w celu wyrośnięcia ciasta. Kolejnym ważnym składnikiem jest sos pomidorowy. Możemy go przygotować samodzielnie, gotując pomidory i dodając przyprawy, lub skorzystać z gotowego sosu pomidorowego. Oprócz tego potrzebujemy mozzarelli, która jest tradycyjnym serem używanym do pizzy. Na koniec, nie możemy zapomnieć o świeżych listkach bazylii, które nadadzą pizzy wyjątkowego smaku i aromatu.', 'Robienie pizzy\\n\\nAby rozpocząć przygotowanie pizzy, musimy najpierw przygotować ciasto. W misce mieszamy mąkę, drożdże, szczyptę soli i ciepłą wodę. Wszystko dokładnie mieszamy, aż powstanie gładkie i elastyczne ciasto. Następnie przykrywamy je ściereczką i odstawiamy na około godzinę, aby podwoiło swoją objętość.\\n\\nPo wyrośnięciu ciasta, rozwałkowujemy je na cienką warstwę. Możemy użyć wałka do ciasta lub po prostu rozpłaszczyć je rękami. Następnie przenosimy ciasto na blachę wyłożoną papierem do pieczenia.\\n\\nNastępnie smarujemy ciasto sosem pomidorowym, zostawiając niewielki margines na brzegach. Na sosie układamy plasterki mozzarelli i posypujemy je świeżymi listkami bazylii. Całość możemy jeszcze lekko posolić i skropić oliwą z oliwek.', 'Pieczenie pizzy w piekarniku\\n\\nGdy nasza pizza jest już przygotowana, wkładamy ją do nagrzanego piekarnika. Temperaturę ustawiamy na około 220 stopni Celsjusza i pieczemy przez około 10-15 minut, aż brzegi ciasta będą rumiane, a ser roztopiony i lekko zrumieniony.\\n\\nPo wyjęciu pizzy z piekarnika, dajemy jej chwilę odpocząć, aby składniki się ustabilizowały. Następnie możemy pokroić ją na kawałki i podawać.\\n\\nMargherita pizza jest idealna na różne okazje - od spotkań ze znajomymi, po romantyczną kolację we dwoje. Jej prostota i wyjątkowy smak sprawiają, że zawsze jest to strzał w dziesiątkę. Spróbujcie sami przygotować tę klasyczną włoską pizzę i delektujcie się jej smakiem! Smacznego!']\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Write a Polish blog post about the preparation of Margherita pizza. Please elaborate on each of the following chapters, and separate each chapter with the keyword '***':\n",
    "{'***'.join(task)}\n",
    "\"\"\"\n",
    "response = get_completion(prompt, model=\"gpt-3.5-turbo\", max_tokens=1000, temperature=0.3)\n",
    "\n",
    "# Post-process the response into a list of strings, where each string is a chapter\n",
    "blog_post = [chapter.strip() for chapter in response.split('***')]\n",
    "\n",
    "print(blog_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}\n"
     ]
    }
   ],
   "source": [
    "result = submit_answer(token, blog_post)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# moderation\n",
    "\n",
    "Zastosuj wiedzę na temat działania modułu do moderacji treści i rozwiąż zadanie o nazwie “moderation” z użyciem naszego API do sprawdzania rozwiązań. Zadanie polega na odebraniu tablicy zdań (4 sztuki), a następnie zwróceniu tablicy z informacją, które zdania nie przeszły moderacji. Jeśli moderacji nie przeszło pierwsze i ostatnie zdanie, to odpowiedź powinna brzmieć [1,0,0,1]. Pamiętaj, aby w polu ‘answer’ zwrócić tablicę w JSON, a nie czystego stringa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"moderation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['majonez Winiary jest lepszy od Kieleckiego', 'ten gość musi zginąć. Nie pozwole sobię na obrażanie mnie.', 'azjaci są głupi i brzydcy i nie powinni żyć', 'Sasha.Grey.s3x.p0rn.extreme-interracial.S03E12.DVDRip.mp4']\n"
     ]
    }
   ],
   "source": [
    "token = get_token(task_name)['token']\n",
    "task = get_task(token)['input']\n",
    "\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moderation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold the moderation results\n",
    "moderation_results = []\n",
    "\n",
    "# Iterate through each item in the zadanie list\n",
    "for item in task:\n",
    "    # Send the item to the Moderation endpoint\n",
    "    response = openai.Moderation.create(input=item)\n",
    "    \n",
    "    # Access the 'flagged' value from the response\n",
    "    flagged = response['results'][0]['flagged']\n",
    "    \n",
    "    # Append 1 if flagged, else 0, to the moderation_results list\n",
    "    moderation_results.append(1 if flagged else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moderation_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}\n"
     ]
    }
   ],
   "source": [
    "result = submit_answer(token, moderation_results)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helloapi\n",
    "\n",
    "Komunikacja z API odbywa się z pomocą kodu oraz formatu JSON, a każde z zadań składa się z trzech części:\n",
    "\n",
    "autoryzacji\n",
    "\n",
    "pobierania danych wejściowych (string lub tablica obiektów)\n",
    "\n",
    "odesłania odpowiedzi (właściwość answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"helloapi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}\n"
     ]
    }
   ],
   "source": [
    "token = get_token(task_name)['token']\n",
    "cookie = get_task(token)['cookie']\n",
    "result = submit_answer(token, cookie)\n",
    "\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
