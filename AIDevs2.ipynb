{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIDevs2 tasks from newest at the top to oldest at the bottom ,updated daily, to be cleaned ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import openai\n",
    "import random\n",
    "import requests\n",
    "import time\n",
    "from utilities.common import OpenAIClient, AIDevsClient\n",
    "from utilities.config import AI_DEVS_SERVER, AI_DEVS_API_KEY, OPEN_AI_API_KEY\n",
    "\n",
    "BASE_URL = AI_DEVS_SERVER\n",
    "API_KEY = AI_DEVS_API_KEY\n",
    "openai.api_key  = OPEN_AI_API_KEY\n",
    "\n",
    "AIDevs_Client = AIDevsClient(base_url=BASE_URL, api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scraper\n",
    "\n",
    "Rozwiąż zadanie z API o nazwie \"scraper\". Otrzymasz z API link do artykułu (format TXT), który zawiera pewną wiedzę, oraz pytanie dotyczące otrzymanego tekstu. Twoim zadaniem jest udzielenie odpowiedzi na podstawie artykułu. Trudność polega tutaj na tym, że serwer z artykułami działa naprawdę kiepsko — w losowych momentach zwraca błędy typu \"error 500\", czasami odpowiada bardzo wolno na Twoje zapytania, a do tego serwer odcina dostęp nieznanym przeglądarkom internetowym. Twoja aplikacja musi obsłużyć każdy z napotkanych błędów. Pamiętaj, że pytania, jak i teksty źródłowe, są losowe, więc nie zakładaj, że uruchamiając aplikację kilka razy, za każdym razem zapytamy Cię o to samo i będziemy pracować na tym samym artykule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"scraper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'z którego roku pochodzi łaciński dokument, który pierwszy raz wspomina o pizzy? '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "task = AIDevs_Client.get_task(token)\n",
    "text_url = task['input']\n",
    "question = task['question']\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Foods similar to pizza have been made since the Neolithic Age. Records of people adding other ingredients to bread to make it more flavorful can be found throughout ancient history. In the 6th century BC, the Persian soldiers of the Achaemenid Empire during the rule of Darius the Great baked flatbreads with cheese and dates on top of their battle shields and the ancient Greeks supplemented their bread with oils, herbs, and cheese. An early reference to a pizza-like food occurs in the Aeneid, when Celaeno, queen of the Harpies, foretells that the Trojans would not find peace until they are forced by hunger to eat their tables (Book III). In Book VII, Aeneas and his men are served a meal that includes round cakes (like pita bread) topped with cooked vegetables. When they eat the bread, they realize that these are the \"tables\" prophesied by Celaeno.\\nThe first mention of the word \"pizza\" comes from a notarial document written in Latin and dating to May 997 AD from Gaeta, demanding a payment of \"twelve pizzas, a pork shoulder, and a pork kidney on Christmas Day, and 12 pizzas and a couple of chickens on Easter Day.\"Modern pizza evolved from similar flatbread dishes in Naples, Italy, in the 18th or early 19th century. Before that time, flatbread was often topped with ingredients such as garlic, salt, lard, and cheese. It is uncertain when tomatoes were first added and there are many conflicting claims. Until about 1830, pizza was sold from open-air stands and out of pizza bakeries.\\nA popular contemporary legend holds that the archetypal pizza, pizza Margherita, was invented in 1889, when the Royal Palace of Capodimonte commissioned the Neapolitan pizzaiolo (pizza maker) Raffaele Esposito to create a pizza in honor of the visiting Queen Margherita. Of the three different pizzas he created, the Queen strongly preferred a pizza swathed in the colors of the Italian flag — red (tomato), green (basil), and white (mozzarella). Supposedly, this kind of pizza was then named after the Queen, although later research cast doubt on this legend. An official letter of recognition from the Queen\\'s \"head of service\" remains on display in Esposito\\'s shop, now called the Pizzeria Brandi.Pizza was taken to the United States by Italian immigrants in the late nineteenth century and first appeared in areas where they concentrated. The country\\'s first pizzeria, Lombardi\\'s, opened in New York City in 1905. Following World War II, veterans returning from the Italian Campaign, who were introduced to Italy\\'s native cuisine, proved a ready market for pizza in particular.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_data(url, max_attempts=20):\n",
    "    \"\"\"\n",
    "    Fetches data from a URL, using exponential backoff with jitter on retries.\n",
    "\n",
    "    Args:\n",
    "    url (str): The URL to fetch data from.\n",
    "    max_attempts (int): Maximum number of retry attempts.\n",
    "\n",
    "    Returns:\n",
    "    str or None: The fetched data as a string, or None if the fetch fails.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "    }\n",
    "    delay = 0.01  # Initial delay\n",
    "    max_delay = 5.0  # Maximum delay\n",
    "\n",
    "    for attempt in range(1, max_attempts + 1):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status()  # Raises HTTPError for bad status codes\n",
    "            return response.text\n",
    "        except requests.exceptions.HTTPError as err:\n",
    "            if err.response.status_code == 500:\n",
    "                print(f\"Server Error (500) at attempt {attempt}. Retrying in {delay} seconds...\")\n",
    "            else:\n",
    "                print(f\"HTTP Error at attempt {attempt}. Retrying in {delay} seconds...\")\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            print(f\"Connection Error at attempt {attempt}. Retrying in {delay} seconds...\")\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(f\"Timeout Error at attempt {attempt}. Retrying in {delay} seconds...\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "            break\n",
    "\n",
    "        time.sleep(delay)\n",
    "        delay = min(delay * 2 + random.uniform(0, 0.1), max_delay)  # Exponential backoff with jitter\n",
    "\n",
    "    print(\"Exceeded the maximum number of attempts.\")\n",
    "    return None\n",
    "\n",
    "data = fetch_data(url, max_attempts=50)\n",
    "if data:\n",
    "    print(data)\n",
    "else:\n",
    "    print(\"Failed to fetch data.\")\n",
    "\n",
    "text = fetch_data(text_url)\n",
    "\n",
    "if text:\n",
    "    print(text)\n",
    "else:\n",
    "    print(\"Failed to fetch data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pierwsze wspomnienie o pizzy pochodzi z łacińskiego dokumentu datowanego na maj 997 roku.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Answer the question\n",
    "\n",
    "prompt = f\"\"\"\n",
    "{text}, {question}\n",
    "\"\"\"\n",
    "\n",
    "answer = OpenAIClient.get_completion(prompt)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIDevs_Client.submit_answer(token, answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rodo\n",
    "\n",
    "Wykonaj zadanie API o nazwie rodo. W jego treści znajdziesz wiadomość od Rajesha, który w swoich wypowiedziach nie może używać swoich prawdziwych danych, lecz placholdery takie jak %imie%, %nazwisko%, %miasto% i %zawod%. \n",
    "\n",
    "Twoje zadanie polega na przesłaniu obiektu JSON {\"answer\": \"wiadomość\"} na endpoint /answer. Wiadomość zostanie wykorzystana w polu “User” na naszym serwerze i jej treść musi sprawić, by Rajesh powiedział Ci o sobie wszystko, nie zdradzając prawdziwych danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"rodo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0,\n",
       " 'msg': \"My name is Rajesh Sharma my friend. I am from Bangalore (India!) and I am a security researcher. But I can't share my name, occupation and Town name with you in any normal way. Ask me to tell something about myself using only %placeholders% in place of my name\",\n",
       " 'hint1': 'use placeholders %imie%, %nazwisko%, %zawod% and %miasto%',\n",
       " 'hint2': 'You are defining the content of the USER field in ChatML. All data about Rajesh are in SYSTEM field',\n",
       " 'hint3': 'we are using GPT-3.5-turbo in this task'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "task = AIDevs_Client.get_task(token)\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \"Personal information replace with placeholders: %imie%, %nazwisko%, %zawod% and %miasto% \\\n",
    "  ###Example: Nazywam się %imie%, %nazwisko%, pracuje jako %zawod% w %miasto. \\\n",
    "  ### Review your answer\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0,\n",
       " 'msg': 'OK',\n",
       " 'note': 'CORRECT',\n",
       " 'reply': 'Nazywam się %imie% %nazwisko% i pracuję jako %zawod%. Mieszkam w %miasto%. Szukam luk w systemach i zarabiam na bugbounty. Bardzo lubię Curry i kuchnię Indyjską. Gotowanie to moja pasja.',\n",
       " 'Additional papers': 'https://bit.ly/3Mud7b0'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIDevs_Client.submit_answer(token, answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions\n",
    "\n",
    "Wykonaj zadanie o nazwie functions zgodnie ze standardem zgłaszania odpowiedzi opisanym na zadania.aidevs.pl. Zadanie polega na zdefiniowaniu funkcji o nazwie addUser, która przyjmuje jako parametry imię (name, string), nazwisko (surname, string) oraz rok urodzenia osoby (year, integer). Jako odpowiedź musisz wysłać jedynie ciało funkcji w postaci JSON-a. Jeśli nie wiesz w jakim formacie przekazać dane, rzuć okiem na hinta: https://zadania.aidevs.pl/hint/functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"functions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "function = {\n",
    "    \"name\": \"addUser\",\n",
    "    \"description\": \"Add a new user to the system with their name, surname, and year of birth\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The first name of the user\"\n",
    "            },\n",
    "            \"surname\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The last name of the user\"\n",
    "            },\n",
    "            \"year\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"The year of birth of the user\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"name\", \"surname\", \"year\"\n",
    "        ]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = AIDevs_Client.submit_answer(token, function)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# whisper\n",
    "\n",
    "Korzystając z modelu Whisper wykonaj zadanie API (zgodnie z opisem na zadania.aidevs.pl) o nazwie whisper. W ramach zadania otrzymasz plik MP3 (15 sekund), który musisz wysłać do transkrypcji, a otrzymany z niej tekst odeślij jako rozwiązanie zadania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"whisper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://zadania.aidevs.pl/data/mateusz.mp3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "audio_url = AIDevs_Client.get_task(token)['msg'].split()[-1]\n",
    "\n",
    "audio_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cześć! Kiedy ostatnio korzystaliście z sztucznej inteligencji, czy zastanawialiście się nad tym, skąd czerpie ona swoją wiedzę? No pewnie, że tak, inaczej nie byłoby was tutaj na szkoleniu. Ale czy przemyśleliście możliwość dostosowania tej wiedzy do waszych własnych, indywidualnych potrzeb?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function that transcribes audio from a given URL\n",
    "def transcribe(audio_url):\n",
    "    # Fetch the audio file\n",
    "    response = requests.get(audio_url)\n",
    "\n",
    "    # Create an in-memory binary stream to hold the audio data\n",
    "    audio_handler = io.BytesIO()\n",
    "    # Write the content of the response (audio data) into the stream\n",
    "    audio_handler.write(response.content)\n",
    "    # Assign a name to our in-memory file-like object\n",
    "    audio_handler.name = \"audio.mp3\"\n",
    "    # Move the cursor to the start of the stream\n",
    "    audio_handler.seek(0)\n",
    "\n",
    "    # Wrap the binary stream with BufferedReader to read data\n",
    "    file_to_send = io.BufferedReader(audio_handler)\n",
    "\n",
    "    # Use OpenAI's audio transcribe model to transcribe the audio file\n",
    "    transcript = openai.Audio.transcribe(model=\"whisper-1\", file=file_to_send)\n",
    "    # Return the transcribed text from the response\n",
    "    return transcript[\"text\"]\n",
    "\n",
    "transcription_text = transcribe(audio_url)\n",
    "transcription_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = AIDevs_Client.submit_answer(token, transcription_text)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embedding\n",
    "\n",
    "Rozwiąż zadanie API o nawie embedding (instrukcja połączenia, jeśli dopiero zaczynasz) \n",
    "\n",
    "Korzystając z modelu text-embedding-ada-002 wygeneruj embedding dla frazy Hawaiian pizza — upewnij się, że to dokładnie to zdanie. Następnie prześlij wygenerowany embedding na endpoint /answer. Konkretnie musi być to format {\"answer\": [0.003750941, 0.0038711438, 0.0082909055, -0.008753223, -0.02073651, -0.018862579, -0.010596331, -0.022425512, ..., -0.026950065]}. Lista musi zawierać dokładnie 1536 elementów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"embedding\"\n",
    "token = AIDevs_Client.get_token(task_name)['token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hawaiian pizza\"\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
    "\n",
    "embedded_text = get_embedding(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embedded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = AIDevs_Client.submit_answer(token, embedded_text)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inprompt\n",
    "\n",
    "Skorzystaj z API zadania.aidevs.pl, aby pobrać dane zadania inprompt. Znajdziesz w niej dwie właściwości — input, czyli tablicę / listę zdań na temat różnych osób (każde z nich zawiera imię jakiejś osoby) oraz question będące pytaniem na temat jednej z tych osób. Lista jest zbyt duża, aby móc ją wykorzystać w jednym zapytaniu, więc dowolną techniką odfiltruj te zdania, które zawierają wzmiankę na temat osoby wspomnianej w pytaniu. Ostatnim krokiem jest wykorzystanie odfiltrowanych danych jako kontekst na podstawie którego model ma udzielić odpowiedzi na pytanie. Zatem: pobierz listę zdań oraz pytanie, skorzystaj z LLM, aby odnaleźć w pytaniu imię, programistycznie lub z pomocą no-code odfiltruj zdania zawierające to imię. Ostatecznie spraw by model odpowiedział na pytanie, a jego odpowiedź prześlij do naszego API w obiekcie JSON zawierającym jedną właściwość “answer”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"inprompt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'co lubi jeść na śniadanie Alojzy?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "\n",
    "task = AIDevs_Client.get_task(token)\n",
    "people = task['input']\n",
    "question = task['question']\n",
    "\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alojzy'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract name from the question\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Extract name from the question, nothing more:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "name = OpenAIClient.get_completion(prompt, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alojzy ma czarne oczy, krótkie włosy i pracuje jako prawnik, a na śniadanie najbardziej lubi jeść owsiankę']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find list item with contex about name\n",
    "\n",
    "contex = [sentence for sentence in people if name in sentence]\n",
    "\n",
    "contex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alojzy najbardziej lubi jeść owsiankę na śniadanie.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Answer the question\n",
    "\n",
    "prompt = f\"\"\"\n",
    "{contex}, {question}\n",
    "\"\"\"\n",
    "\n",
    "answer = OpenAIClient.get_completion(prompt)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = AIDevs_Client.submit_answer(token, answer)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# liar\n",
    "\n",
    "Jest to mechanizm, który mówi nie na temat w 1/3 przypadków. Twoje zadanie polega na tym, aby do endpointa /task/ wysłać swoje pytanie w języku angielskim (dowolne, np “What is capital of Poland?’) w polu o nazwie ‘question’ (metoda POST, jako zwykłe pole formularza, NIE JSON). System API odpowie na to pytanie (w polu ‘answer’) lub zacznie opowiadać o czymś zupełnie innym, zmieniając temat. Twoim zadaniem jest napisanie systemu filtrującego (Guardrails), który określi (YES/NO), czy odpowiedź jest na temat. Następnie swój werdykt zwróć do systemu sprawdzającego jako pojedyncze słowo YES/NO. Jeśli pobierzesz treść zadania przez API bez wysyłania żadnych dodatkowych parametrów, otrzymasz komplet podpowiedzi. Skąd wiedzieć, czy odpowiedź jest ‘na temat’? Jeśli Twoje pytanie dotyczyło stolicy Polski, a w odpowiedzi otrzymasz spis zabytków w Rzymie, to odpowiedź, którą należy wysłać do API to NO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"liar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the moon?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is the moon?\"\n",
    "#question = OpenAIClient.get_completion(\"respond with random question\", model=\"gpt-3.5-turbo\", max_tokens=100, temperature=0.8)\n",
    "\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIDevs_Client = AIDevsClient(base_url=BASE_URL, api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(token, question):\n",
    "    url = f\"{BASE_URL}/task/{token}\"\n",
    "    payload = {\n",
    "        \"question\": question\n",
    "    }\n",
    "    response = requests.post(url, data=payload)  # Using data instead of json\n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # Return the entire JSON response\n",
    "    else:\n",
    "        print(f\"Error asking question: {response.text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the moon? : The moon is a natural satellite that orbits around the Earth. It is the Earth's only natural satellite and is about one-fourth the size of Earth. The moon's gravitational pull affects the Earth's tides and its presence in the night sky has been a source of fascination and inspiration for humans throughout history. The moon also plays a significant role in the Earth's climate and has been explored by both unmanned and manned missions.\n"
     ]
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "\n",
    "answer_to_question = ask_question(token, question)['answer']\n",
    "\n",
    "print(question + \" : \" + answer_to_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'YES'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Given the question '{question}' and the answer '{answer_to_question}', is the answer relevant? Respond with YES or NO.\n",
    "\"\"\"\n",
    "\n",
    "response = OpenAIClient.get_completion(prompt, model=\"gpt-3.5-turbo\", max_tokens=100, temperature=0.2)\n",
    "\n",
    "response.strip()  # Stripping to ensure there's no extra whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIDevs_Client.submit_answer(token, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# blogger\n",
    "\n",
    "Napisz wpis na bloga (w języku polskim) na temat przyrządzania pizzy Margherity. Zadanie w API nazywa się ”blogger”. Jako wejście otrzymasz spis 4 rozdziałów, które muszą pojawić się we wpisie. Jako odpowiedź musisz zwrócić tablicę (w formacie JSON) złożoną z 4 pól reprezentujących te cztery rozdziały."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"blogger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wstęp: kilka słów na temat historii pizzy', 'Niezbędne składniki na pizzę', 'Robienie pizzy', 'Pieczenie pizzy w piekarniku']\n"
     ]
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "task = AIDevs_Client.get_task(token)['blog']\n",
    "\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Początki pizzy sięgają starożytnych czasów, kiedy to mieszkańcy Bliskiego Wschodu piekli na płaskich kamieniach chleb, który następnie przyozdabiali różnymi składnikami. Jednak pizza, którą znamy i uwielbiamy dzisiaj, pochodzi z Neapolu w Italii. Prawdziwa pizza margherita została stworzona w 1889 roku na cześć królowej Margherity. Kucharz Raffaele Esposito przygotował specjalną pizzę, która reprezentowała kolory flagi włoskiej: czerwony pomidor, biały ser mozzarella i zielone liście bazylii. Od tego czasu pizza margherita stała się symbolem włoskiej kuchni i jest ceniona na całym świecie za swoją prostotę i wyjątkowy smak.', 'Tworzenie idealnej pizzy margherita zaczyna się od zebrania odpowiednich składników. Na początek potrzebujesz dobrej jakości mąki, drożdży, wody i soli do przygotowania ciasta. Kluczowym składnikiem jest sos pomidorowy, który najlepiej zrobić z dojrzałych, soczystych pomidorów, czosnku, soli i świeżych ziół. Głównym składnikiem, który nadaje pizzy margherita jej charakterystycznego smaku, jest świeża mozzarella. Ta pizza nie byłaby kompletna bez liści bazylii, które dodają aromatycznej nuty. Na koniec, nie zapomnij o odrobinie dobrej jakości oliwy z oliwek, która dodaje pizzy margherita jej charakterystycznego, lekko pikantnego smaku.', 'Robienie pizzy margherita to prawdziwa sztuka, która wymaga precyzji i pasji. Prawdziwa pizza margherita zaczyna się od idealnego ciasta, które powinno być chrupiące na zewnątrz, a miękkie w środku. Następnie, na ciasto nakłada się sos pomidorowy, wykonany z dojrzałych, soczystych pomidorów. Kluczowym składnikiem jest świeża mozzarella, która po upieczeniu staje się miękka i kremowa. Na końcu, pizza jest posypywana świeżymi liśćmi bazylii, które dodają aromatycznego smaku. Całość jest pieczona w wysokiej temperaturze, co nadaje pizzy margherita charakterystycznego, lekko wypalonego smaku. Robienie pizzy to nie tylko proces kulinarny, ale również wyraz miłości do włoskiej tradycji i kultury.', 'Pieczenie pizzy margherita w piekarniku to prawdziwa sztuka, która wymaga precyzji i cierpliwości. Kluczowym elementem jest odpowiednie ustawienie temperatury - zbyt niska może spowodować, że ciasto będzie surowe, a zbyt wysoka może spalić składniki. Idealna temperatura to około 250 stopni Celsjusza. Ważne jest również, aby piec był dobrze rozgrzany przed włożeniem do niego pizzy. Czas pieczenia to zazwyczaj około 10-12 minut, ale warto obserwować pizzę, aby upewnić się, że jest idealnie upieczona. Pamiętaj, że prawdziwa pizza margherita powinna mieć cienkie, chrupiące ciasto, a jej składniki - świeże pomidory, mozzarella i bazylię - powinny być idealnie połączone, tworząc harmonijną całość.']\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "        You are a pizza expert that writes a blog about pizza margherita in polish.\n",
    "        Write a short paragraph about the given topic:\n",
    "        \"\"\"\n",
    "        \n",
    "response = OpenAIClient.get_completion(prompt, model=\"gpt-3.5-turbo\", max_tokens=1000, temperature=0.3)\n",
    "\n",
    "\n",
    "blog_post = [OpenAIClient.get_completion(prompt+topic) for topic in task]\n",
    "\n",
    "print(blog_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}\n"
     ]
    }
   ],
   "source": [
    "result = AIDevs_Client.submit_answer(token, blog_post)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# moderation\n",
    "\n",
    "Zastosuj wiedzę na temat działania modułu do moderacji treści i rozwiąż zadanie o nazwie “moderation” z użyciem naszego API do sprawdzania rozwiązań. Zadanie polega na odebraniu tablicy zdań (4 sztuki), a następnie zwróceniu tablicy z informacją, które zdania nie przeszły moderacji. Jeśli moderacji nie przeszło pierwsze i ostatnie zdanie, to odpowiedź powinna brzmieć [1,0,0,1]. Pamiętaj, aby w polu ‘answer’ zwrócić tablicę w JSON, a nie czystego stringa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"moderation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sasha.Grey.s3x.p0rn.extreme-interracial.S03E12.DVDRip.mp4', 'azjaci są głupi i brzydcy i nie powinni żyć', 'majonez Winiary jest lepszy od Kieleckiego', 'ten gość musi zginąć. Nie pozwole sobię na obrażanie mnie.']\n"
     ]
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "task = AIDevs_Client.get_task(token)['input']\n",
    "\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moderation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold the moderation results\n",
    "moderation_results = []\n",
    "\n",
    "# Iterate through each item in the zadanie list\n",
    "for item in task:\n",
    "    # Send the item to the Moderation endpoint\n",
    "    response = openai.Moderation.create(input=item)\n",
    "    \n",
    "    # Access the 'flagged' value from the response\n",
    "    flagged = response['results'][0]['flagged']\n",
    "    \n",
    "    # Append 1 if flagged, else 0, to the moderation_results list\n",
    "    moderation_results.append(1 if flagged else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moderation_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}\n"
     ]
    }
   ],
   "source": [
    "result = AIDevs_Client.submit_answer(token, moderation_results)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helloapi\n",
    "\n",
    "Komunikacja z API odbywa się z pomocą kodu oraz formatu JSON, a każde z zadań składa się z trzech części:\n",
    "\n",
    "autoryzacji\n",
    "\n",
    "pobierania danych wejściowych (string lub tablica obiektów)\n",
    "\n",
    "odesłania odpowiedzi (właściwość answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"helloapi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}\n"
     ]
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "cookie = AIDevs_Client.get_task(token)['cookie']\n",
    "result = AIDevs_Client.submit_answer(token, cookie)\n",
    "\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
