{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIDevs2 tasks from newest at the top to oldest at the bottom ,updated daily, to be cleaned ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from utilities.common import OpenAIClient, AIDevsClient\n",
    "from utilities.config import AI_DEVS_SERVER, AI_DEVS_API_KEY, OPEN_AI_API_KEY, qdrant_url\n",
    "\n",
    "BASE_URL = AI_DEVS_SERVER\n",
    "\n",
    "OpenAIClient = OpenAIClient(api_key=OPEN_AI_API_KEY)\n",
    "AIDevs_Client = AIDevsClient(base_url=BASE_URL, api_key=AI_DEVS_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tools\n",
    "\n",
    "Celem zadania jest zdecydowanie, czy podane przez API zadanie powinno zostać dodane do listy zadań (ToDo), czy do kalendarza (jeśli ma ustaloną datę). Oba narzędzia mają lekko definicje struktury JSON-a (różnią się jednym polem). Spraw, aby Twoja aplikacja działała poprawnie na każdym zestawie danych testowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"tools\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "question = AIDevs_Client.get_task(token)['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# get dodays date\n",
    "today = str(datetime.date.today())\n",
    "\n",
    "prompt = \"It is:\" + today + \" today. \"+ question\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"ToDo\",\n",
    "            \"description\": \"If date is not provided, add to ToDo list\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"desc\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"desctription of the task\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"desc\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"Calendar\",\n",
    "            \"description\": \"If date is provided, Add task to the calendar\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {                  \n",
    "                    \"desc\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"description of the event\",\n",
    "                    },\n",
    "                    \"date\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"date in format YYYY-MM-DD when message contains time information\",\n",
    "                        \"format\": \"date\"  # Ensures the date is in the correct format\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"desc\", \"date\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "response = OpenAIClient.get_completion_use_tools(\n",
    "    #model=\"gpt-3.5-turbo-1106\",\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    prompt=prompt,\n",
    "    tools=tools\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"tool\": \"Calendar\",\n",
      "    \"desc\": \"Kup 1kg ziemniak\\u00f3w\",\n",
      "    \"date\": \"2023-11-23\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response_message = response.choices[0].message\n",
    "\n",
    "tool_call = response_message.tool_calls[0]  # Get the first tool call\n",
    "\n",
    "# Extract the function name\n",
    "function_name = tool_call.function.name\n",
    "\n",
    "# Extract the arguments from the function attribute and parse the JSON string\n",
    "function_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "# Combine the function name and arguments into a single JSON object\n",
    "combined_json = {\n",
    "    \"tool\": function_name,\n",
    "    **function_args  # This unpacks the parsed arguments into the new JSON object\n",
    "}\n",
    "\n",
    "print(json.dumps(combined_json, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIDevs_Client.submit_answer(token, combined_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# knowledge\n",
    "\n",
    "Automat zada Ci losowe pytanie na temat kursu walut, populacji wybranego kraju lub wiedzy ogólnej. Twoim zadaniem jest wybór odpowiedniego narzędzia do udzielenia odpowiedzi (API z wiedzą lub skorzystanie z wiedzy modelu). W treści zadania uzyskanego przez API, zawarte są dwa API, które mogą być dla Ciebie użyteczne.  \n",
    "\n",
    "'database #1': 'Currency http://api.nbp.pl/en.html (use table A)',\n",
    "'database #2': \"Knowledge about countries https://restcountries.com/ - field 'population'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"knowledge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kto napisał Romeo i Julię?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "question = AIDevs_Client.get_task(token)['question']\n",
    "question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function Calling sollution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upgrade openai with the latest framework (version 1.0.0)\n",
    "\n",
    "#!pip install --upgrade openai\n",
    "\n",
    "import openai\n",
    "\n",
    "openai.api_key  = OPEN_AI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define functions for tools\n",
    "\n",
    "def make_http_request(url):\n",
    "    \"\"\"Make an HTTP GET request and return the JSON response.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def check_rate(currency_code):\n",
    "    \"\"\"Check the exchange rate for a given currency code.\"\"\"\n",
    "    url = f\"http://api.nbp.pl/api/exchangerates/rates/a/{currency_code}/?format=json\"\n",
    "    data = make_http_request(url)\n",
    "\n",
    "    if data:\n",
    "        answer = data['rates'][0]['mid']\n",
    "        print(f\"Exchange rate for {currency_code}: {answer}\")\n",
    "        return answer\n",
    "    else:\n",
    "        print(f\"Failed to get exchange rate for {currency_code}\")\n",
    "\n",
    "def check_population(country_name):\n",
    "    \"\"\"Check the population of a given country.\"\"\"\n",
    "    url = f\"https://restcountries.com/v3.1/name/{country_name}\"\n",
    "    data = make_http_request(url)\n",
    "\n",
    "    if data:\n",
    "        answer = data[0]['population']\n",
    "        print(f\"Population of {country_name}: {answer}\")\n",
    "        return answer\n",
    "    else:\n",
    "        print(f\"Failed to get population for {country_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: kto napisał Romeo i Julię?\n",
      "Function Name: other_question\n",
      "Argument Value: {'answer': \"Romeo i Julia zostało napisane przez Williama Shakespeare'a.\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": question\n",
    "    }\n",
    "]\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"check_rate\",\n",
    "            \"description\": \"Check Exchange Rate\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"3_letter_code\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"3 letter currency code\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"3_letter_code\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"check_population\",\n",
    "            \"description\": \"Check population of the country\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"country_name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Country name\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"country_name\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"other_question\",\n",
    "            \"description\": \"Answer the question\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"answer\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Answer to the question\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"answer\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    #model=\"gpt-3.5-turbo-1106\",\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "# Assuming response is the response object from the OpenAI API\n",
    "response_message = response.choices[0].message\n",
    "tool_call = response_message.tool_calls[0]\n",
    "\n",
    "# Extract function name\n",
    "function_name = tool_call.function.name\n",
    "\n",
    "# Parse the arguments JSON and extract the first value\n",
    "arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "print(f\"Question: {question}\\nFunction Name: {function_name}\\nArgument Value: {arguments}\")\n",
    "\n",
    "functions = {\n",
    "    'check_rate': check_rate,\n",
    "    'check_population': check_population,\n",
    "    'other_question': \"GPT answer\"\n",
    "}\n",
    "\n",
    "# Call the function\n",
    "if function_name in functions:\n",
    "    # Extract the first argument value if it's not 'other_question'\n",
    "    if function_name != 'other_question':\n",
    "        arg_value = next(iter(arguments.values()))\n",
    "        answer = functions[function_name](arg_value)\n",
    "    else:\n",
    "        # For 'other_question', pass the entire arguments dictionary\n",
    "        answer = arguments['answer']\n",
    "else:\n",
    "    answer = \"Unknown function\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIDevs_Client.submit_answer(token, answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanilla sollution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 'population' | Value to pass to API: 'Germany'\n"
     ]
    }
   ],
   "source": [
    "#Classify the topic of the question and value for related API (another option is to parse response depending on leght of it: 3 for currency, 3-10 for country and 11+ for other)\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Clasyfy following question to topics: currency/population/other_topic:\n",
    "{question}\n",
    "\n",
    "answer with JSON \"currency/population/other_topic\":\"3letter_currency_code/country_name/oryginal_question\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "topic, value = list(json.loads(OpenAIClient.get_completion(prompt, temperature=0.1)).items())[0]\n",
    "\n",
    "print(f\"Topic: '{topic}' | Value to pass to API: '{value}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83240525"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Send request to API depending on the topic\n",
    "\n",
    "def get_api_data(request_type, identifier):\n",
    "    # Determine the API's URL based on the request type\n",
    "    if request_type == \"currency\":\n",
    "        url = f\"http://api.nbp.pl/api/exchangerates/rates/a/{identifier}/?format=json\"\n",
    "    elif request_type == \"population\":\n",
    "        url = f\"https://restcountries.com/v3.1/name/{identifier}\"\n",
    "    # Send question to GPT API if it doesn't fit any category.\n",
    "    else:\n",
    "        return OpenAIClient.get_completion(f\"answer: {identifier}\", temperature=0.1)\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            # Extract and return the relevant information based on the request type\n",
    "            if request_type == \"currency\":\n",
    "                return data['rates'][0]['mid']\n",
    "            elif request_type == \"population\":\n",
    "                return data[0]['population']\n",
    "        else:\n",
    "            return f\"Error: Received status code {response.status_code} from the API.\"\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "answer = get_api_data(topic, value)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIDevs_Client.submit_answer(token, answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# people\n",
    "\n",
    "Pobierz, a następnie zoptymalizuj odpowiednio pod swoje potrzeby bazę danych https://zadania.aidevs.pl/data/people.json Twoim zadaniem jest odpowiedź na pytanie zadane przez system. Uwaga! Pytanie losuje się za każdym razem na nowo, gdy odwołujesz się do /task. Spraw, aby Twoje rozwiązanie działało za każdym razem, a także, aby zużywało możliwie mało tokenów. Zastanów się, czy wszystkie operacje muszą być wykonywane przez LLM-a - może warto zachować jakiś balans między światem kodu i AI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"people\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into DataFrame successfully.\n",
      "Number of rows in the DataFrame: 1387\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imie</th>\n",
       "      <th>nazwisko</th>\n",
       "      <th>wiek</th>\n",
       "      <th>o_mnie</th>\n",
       "      <th>ulubiona_postac_z_kapitana_bomby</th>\n",
       "      <th>ulubiony_serial</th>\n",
       "      <th>ulubiony_film</th>\n",
       "      <th>ulubiony_kolor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dariusz</td>\n",
       "      <td>Kaczor</td>\n",
       "      <td>46</td>\n",
       "      <td>niekiedy lubie jeść lody. Mieszkam w Radomiu. ...</td>\n",
       "      <td>Admirał Gwiezdnej Floty</td>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>Avengers</td>\n",
       "      <td>morski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Katarzyna</td>\n",
       "      <td>Rumcajs</td>\n",
       "      <td>32</td>\n",
       "      <td>lubie zjadać lody. Mieszkam w Łodzi. Interesuj...</td>\n",
       "      <td>nie oglądam</td>\n",
       "      <td>Big Bang Theory</td>\n",
       "      <td>The Lord of the Rings</td>\n",
       "      <td>magenta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Renata</td>\n",
       "      <td>Pizza</td>\n",
       "      <td>49</td>\n",
       "      <td>czasami lubie zjadać pizzę. Mieszkam w Łodzi. ...</td>\n",
       "      <td>nie pamiętam tych wsystkich imion</td>\n",
       "      <td>Walking Dead</td>\n",
       "      <td>The Prestige</td>\n",
       "      <td>czerwony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Katarzyna</td>\n",
       "      <td>Kot</td>\n",
       "      <td>61</td>\n",
       "      <td>niekiedy lubie jeść pizzę. Mieszkam w Krakowie...</td>\n",
       "      <td>nie pamiętam tych wsystkich imion</td>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>Titanic</td>\n",
       "      <td>oliwkowy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Władysław</td>\n",
       "      <td>Bajorko</td>\n",
       "      <td>24</td>\n",
       "      <td>niekiedy lubie jeść pizzę. Mieszkam w Poznaniu...</td>\n",
       "      <td>nie oglądam</td>\n",
       "      <td>LOST</td>\n",
       "      <td>The Sixth Sense</td>\n",
       "      <td>malinowy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        imie nazwisko  wiek  \\\n",
       "0    Dariusz   Kaczor    46   \n",
       "1  Katarzyna  Rumcajs    32   \n",
       "2     Renata    Pizza    49   \n",
       "3  Katarzyna      Kot    61   \n",
       "4  Władysław  Bajorko    24   \n",
       "\n",
       "                                              o_mnie  \\\n",
       "0  niekiedy lubie jeść lody. Mieszkam w Radomiu. ...   \n",
       "1  lubie zjadać lody. Mieszkam w Łodzi. Interesuj...   \n",
       "2  czasami lubie zjadać pizzę. Mieszkam w Łodzi. ...   \n",
       "3  niekiedy lubie jeść pizzę. Mieszkam w Krakowie...   \n",
       "4  niekiedy lubie jeść pizzę. Mieszkam w Poznaniu...   \n",
       "\n",
       "    ulubiona_postac_z_kapitana_bomby  ulubiony_serial          ulubiony_film  \\\n",
       "0            Admirał Gwiezdnej Floty  Stranger Things               Avengers   \n",
       "1                        nie oglądam  Big Bang Theory  The Lord of the Rings   \n",
       "2  nie pamiętam tych wsystkich imion     Walking Dead           The Prestige   \n",
       "3  nie pamiętam tych wsystkich imion  Game of Thrones                Titanic   \n",
       "4                        nie oglądam             LOST        The Sixth Sense   \n",
       "\n",
       "  ulubiony_kolor  \n",
       "0         morski  \n",
       "1        magenta  \n",
       "2       czerwony  \n",
       "3       oliwkowy  \n",
       "4       malinowy  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URL of the JSON file\n",
    "url = 'https://zadania.aidevs.pl/data/people.json'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON content into a DataFrame\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data)\n",
    "    print(\"Data loaded into DataFrame successfully.\")\n",
    "else:\n",
    "    print(\"Failed to download the file. Status code:\", response.status_code)\n",
    "\n",
    "print(\"Number of rows in the DataFrame:\", df.shape[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in cleaned DataFrame: 1387\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imie</th>\n",
       "      <th>nazwisko</th>\n",
       "      <th>ulubiony_kolor</th>\n",
       "      <th>ulubione_jedzenie</th>\n",
       "      <th>miejscowosc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dariusz</td>\n",
       "      <td>Kaczor</td>\n",
       "      <td>morski</td>\n",
       "      <td>lody</td>\n",
       "      <td>Radomiu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Katarzyna</td>\n",
       "      <td>Rumcajs</td>\n",
       "      <td>magenta</td>\n",
       "      <td>lody</td>\n",
       "      <td>Łodzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Renata</td>\n",
       "      <td>Pizza</td>\n",
       "      <td>czerwony</td>\n",
       "      <td>pizza</td>\n",
       "      <td>Łodzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Katarzyna</td>\n",
       "      <td>Kot</td>\n",
       "      <td>oliwkowy</td>\n",
       "      <td>pizza</td>\n",
       "      <td>Krakowie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Władysław</td>\n",
       "      <td>Bajorko</td>\n",
       "      <td>malinowy</td>\n",
       "      <td>pizza</td>\n",
       "      <td>Poznaniu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        imie nazwisko ulubiony_kolor ulubione_jedzenie miejscowosc\n",
       "0    Dariusz   Kaczor         morski              lody     Radomiu\n",
       "1  Katarzyna  Rumcajs        magenta              lody       Łodzi\n",
       "2     Renata    Pizza       czerwony             pizza       Łodzi\n",
       "3  Katarzyna      Kot       oliwkowy             pizza    Krakowie\n",
       "4  Władysław  Bajorko       malinowy             pizza    Poznaniu"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean the DataFrame to retain only relevant information (favourite colour, favourite food, place of residence, last name, name)\n",
    "\n",
    "# Extracting favorite food from the 'o_mnie' column\n",
    "df['ulubione_jedzenie'] = df['o_mnie'].apply(lambda x: 'lody' if 'lody' in x else 'pizza')\n",
    "\n",
    "# Extracting place of residence from the 'o_mnie' column\n",
    "df['miejscowosc'] = df['o_mnie'].str.extract(r'Mieszkam w (\\w+)')\n",
    "\n",
    "# Selecting only the relevant columns\n",
    "df = df[['imie', 'nazwisko', 'ulubiony_kolor', 'ulubione_jedzenie', 'miejscowosc']]\n",
    "\n",
    "print(\"Number of rows in cleaned DataFrame:\", df.shape[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'powiedz mi, gdzie mieszka Katarzyna Truskawka? w jakim mieście?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "question = AIDevs_Client.get_task(token)['question'] #The question will change every time the task is called. I only ask about favourite colour, favourite food and place of residence. example: \"co lubi jeść Tomek Bzik?\" \"Gdzie mieszka Krysia Ludek?\"\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytanie: powiedz mi, gdzie mieszka Katarzyna Truskawka? w jakim mieście?\n",
      "Imię: Katarzyna\n",
      "Nazwisko: Truskawka\n",
      "Temat: miejscowosc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to parse the question and extract name, surname, and topic\n",
    "def parse_question(question):\n",
    "    # Extracting the last two capitalized words as name and surname\n",
    "    name_surname_match = re.findall(r'([A-Z][a-z]+) ([A-Z][a-z]+)', question)\n",
    "    name, surname = name_surname_match[0]\n",
    "\n",
    "    # Determining the topic of the question\n",
    "    if \"kolor\" in question:\n",
    "        topic = \"ulubiony_kolor\"\n",
    "    elif \"jeść\" in question:\n",
    "        topic = \"ulubione_jedzenie\"\n",
    "    else:\n",
    "        topic = \"miejscowosc\"\n",
    "\n",
    "    return name, surname, topic\n",
    "\n",
    "name, surname, topic = parse_question(question)\n",
    "print(f\"Pytanie: {question}\\nImię: {name}\\nNazwisko: {surname}\\nTemat: {topic}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytanie: powiedz mi, gdzie mieszka Katarzyna Truskawka? w jakim mieście?\n",
      "Odpowiedź: Wrocławiu\n"
     ]
    }
   ],
   "source": [
    "# Find the answer in the DataFrame\n",
    "def find_answer(df, name, surname, topic):\n",
    "    if not name or not surname or not topic:\n",
    "        return \"Nie znaleziono informacji.\"\n",
    "\n",
    "    # Shortening the name and surname by removing the last three characters \n",
    "    shortened_name = name[:-3]\n",
    "    shortened_surname = surname[:-3]\n",
    "\n",
    "    # Querying the DataFrame for the relevant information\n",
    "    result = df.loc[(df['imie'].str.startswith(shortened_name)) & \n",
    "                    (df['nazwisko'].str.startswith(shortened_surname)), topic]\n",
    "    \n",
    "    if not result.empty:\n",
    "        return result.iloc[0]\n",
    "    else:\n",
    "        return \"Nie znaleziono informacji.\"\n",
    "\n",
    "#name, surname, topic = \"Katarzyna\", \"Truskawka\", \"miejscowosc\"\n",
    "answer = find_answer(df, name, surname, topic)\n",
    "print(f\"Pytanie: {question}\\nOdpowiedź: {answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Katarzyna Truskawka mieszka we Wrocławiu.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Answer the question with LLM\n",
    "\n",
    "prompt = f\"\"\"\n",
    "odpowiedz na pytanie:\n",
    "{question} ({answer})\n",
    "\"\"\"\n",
    "\n",
    "answer = OpenAIClient.get_completion(prompt)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIDevs_Client.submit_answer(token, answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# search\n",
    "\n",
    "Zaimportuj do swojej bazy wektorowej, spis wszystkich linków z newslettera unknowNews z adresu:\n",
    "https://unknow.news/archiwum.json\n",
    "[jeśli zależy Ci na czasie, możesz dodać pierwsze 300 rekordów]\n",
    "\n",
    "Następnie wykonaj zadanie API o nazwie “search” — odpowiedz w nim na zwrócone przez API pytanie. Odpowiedź musi być adresem URL kierującym do jednego z linków unknowNews. Powodzenia! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Co różni pseudonimizację od anonimizowania danych?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "question = AIDevs_Client.get_task(token)['question']\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into DataFrame successfully.\n"
     ]
    }
   ],
   "source": [
    "# URL of the JSON file\n",
    "url = 'https://unknow.news/archiwum.json'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON content into a DataFrame\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data)\n",
    "    print(\"Data loaded into DataFrame successfully.\")\n",
    "else:\n",
    "    print(\"Failed to download the file. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the DataFrame: 6153\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>info</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Niesamowite \"Roboty\" sprzed setek lat - jak to...</td>\n",
       "      <td>https://www.youtube.com/watch?v=6Nt7xLAfEPs</td>\n",
       "      <td>INFO: Z pewnością znasz figurki poruszające si...</td>\n",
       "      <td>2023-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ostatni event Apple nagrano iPhonem 15 Pro Max...</td>\n",
       "      <td>https://prolost.com/blog/scarybts</td>\n",
       "      <td>INFO: Prawdą jest, że wydarzenie zostało od po...</td>\n",
       "      <td>2023-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dlaczego tylko 1% archiwum Snowdena kiedykolwi...</td>\n",
       "      <td>https://www.computerweekly.com/news/366554957/...</td>\n",
       "      <td>INFO: Pierwsze wycieki Snowdena ujrzały światł...</td>\n",
       "      <td>2023-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lista 10 trudnych do przełknięcia prawd o prac...</td>\n",
       "      <td>https://www.mensurdurakovic.com/hard-to-swallo...</td>\n",
       "      <td>INFO: Dla jednych może to być oczywistość, ale...</td>\n",
       "      <td>2023-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Były mechanik Tesli ujawnił sekrety firmy?</td>\n",
       "      <td>https://elektrowoz.pl/transport/polak-byly-mec...</td>\n",
       "      <td>INFO: Jak wygląda praca u jednego z najbardzie...</td>\n",
       "      <td>2023-11-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Niesamowite \"Roboty\" sprzed setek lat - jak to...   \n",
       "1  Ostatni event Apple nagrano iPhonem 15 Pro Max...   \n",
       "2  Dlaczego tylko 1% archiwum Snowdena kiedykolwi...   \n",
       "3  Lista 10 trudnych do przełknięcia prawd o prac...   \n",
       "4         Były mechanik Tesli ujawnił sekrety firmy?   \n",
       "\n",
       "                                                 url  \\\n",
       "0        https://www.youtube.com/watch?v=6Nt7xLAfEPs   \n",
       "1                  https://prolost.com/blog/scarybts   \n",
       "2  https://www.computerweekly.com/news/366554957/...   \n",
       "3  https://www.mensurdurakovic.com/hard-to-swallo...   \n",
       "4  https://elektrowoz.pl/transport/polak-byly-mec...   \n",
       "\n",
       "                                                info        date  \n",
       "0  INFO: Z pewnością znasz figurki poruszające si...  2023-11-10  \n",
       "1  INFO: Prawdą jest, że wydarzenie zostało od po...  2023-11-10  \n",
       "2  INFO: Pierwsze wycieki Snowdena ujrzały światł...  2023-11-10  \n",
       "3  INFO: Dla jednych może to być oczywistość, ale...  2023-11-10  \n",
       "4  INFO: Jak wygląda praca u jednego z najbardzie...  2023-11-10  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of rows in the DataFrame:\", df.shape[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>info</th>\n",
       "      <th>date</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Niesamowite \"Roboty\" sprzed setek lat - jak to...</td>\n",
       "      <td>https://www.youtube.com/watch?v=6Nt7xLAfEPs</td>\n",
       "      <td>INFO: Z pewnością znasz figurki poruszające si...</td>\n",
       "      <td>2023-11-10</td>\n",
       "      <td>[-0.015934249386191368, -0.018720140680670738,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ostatni event Apple nagrano iPhonem 15 Pro Max...</td>\n",
       "      <td>https://prolost.com/blog/scarybts</td>\n",
       "      <td>INFO: Prawdą jest, że wydarzenie zostało od po...</td>\n",
       "      <td>2023-11-10</td>\n",
       "      <td>[-0.0012809549225494266, -0.016229121014475822...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dlaczego tylko 1% archiwum Snowdena kiedykolwi...</td>\n",
       "      <td>https://www.computerweekly.com/news/366554957/...</td>\n",
       "      <td>INFO: Pierwsze wycieki Snowdena ujrzały światł...</td>\n",
       "      <td>2023-11-10</td>\n",
       "      <td>[0.0013147342251613736, 0.00323414895683527, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lista 10 trudnych do przełknięcia prawd o prac...</td>\n",
       "      <td>https://www.mensurdurakovic.com/hard-to-swallo...</td>\n",
       "      <td>INFO: Dla jednych może to być oczywistość, ale...</td>\n",
       "      <td>2023-11-10</td>\n",
       "      <td>[0.010727036744356155, -0.01237734965980053, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Były mechanik Tesli ujawnił sekrety firmy?</td>\n",
       "      <td>https://elektrowoz.pl/transport/polak-byly-mec...</td>\n",
       "      <td>INFO: Jak wygląda praca u jednego z najbardzie...</td>\n",
       "      <td>2023-11-10</td>\n",
       "      <td>[0.014562682248651981, -0.014329886063933372, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Niesamowite \"Roboty\" sprzed setek lat - jak to...   \n",
       "1  Ostatni event Apple nagrano iPhonem 15 Pro Max...   \n",
       "2  Dlaczego tylko 1% archiwum Snowdena kiedykolwi...   \n",
       "3  Lista 10 trudnych do przełknięcia prawd o prac...   \n",
       "4         Były mechanik Tesli ujawnił sekrety firmy?   \n",
       "\n",
       "                                                 url  \\\n",
       "0        https://www.youtube.com/watch?v=6Nt7xLAfEPs   \n",
       "1                  https://prolost.com/blog/scarybts   \n",
       "2  https://www.computerweekly.com/news/366554957/...   \n",
       "3  https://www.mensurdurakovic.com/hard-to-swallo...   \n",
       "4  https://elektrowoz.pl/transport/polak-byly-mec...   \n",
       "\n",
       "                                                info        date  \\\n",
       "0  INFO: Z pewnością znasz figurki poruszające si...  2023-11-10   \n",
       "1  INFO: Prawdą jest, że wydarzenie zostało od po...  2023-11-10   \n",
       "2  INFO: Pierwsze wycieki Snowdena ujrzały światł...  2023-11-10   \n",
       "3  INFO: Dla jednych może to być oczywistość, ale...  2023-11-10   \n",
       "4  INFO: Jak wygląda praca u jednego z najbardzie...  2023-11-10   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.015934249386191368, -0.018720140680670738,...  \n",
       "1  [-0.0012809549225494266, -0.016229121014475822...  \n",
       "2  [0.0013147342251613736, 0.00323414895683527, 0...  \n",
       "3  [0.010727036744356155, -0.01237734965980053, 0...  \n",
       "4  [0.014562682248651981, -0.014329886063933372, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_embedding_na(embedding):\n",
    "    # Check if the embedding is NaN or None\n",
    "    if embedding is None:\n",
    "        return True\n",
    "    if isinstance(embedding, list):\n",
    "        return all(pd.isna(x) for x in embedding)\n",
    "    return pd.isna(embedding)\n",
    "\n",
    "# Initialize the 'embedding' column with NaN if it doesn't exist\n",
    "if 'embedding' not in df.columns:\n",
    "    df['embedding'] = pd.NA\n",
    "\n",
    "# Apply the get_embedding function only for rows without an existing embedding\n",
    "df['embedding'] = df.apply(lambda row: OpenAIClient.get_embedding(row['info']) \n",
    "                           if is_embedding_na(row['embedding']) \n",
    "                           else row['embedding'], axis=1)\n",
    "\n",
    "#df.to_pickle(\"unknow_news.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_pickle(\"unknow_news.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the get_embedding function to the question\n",
    "question_embedding = OpenAIClient.get_embedding(question)\n",
    "\n",
    "#print(question_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "local solution, uses Pandas and Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Co różni pseudonimizację od anonimizowania danych? Title: Czym się różni pseudonimizacja od anonimizacji? (film, 46 minut) URL: https://www.internet-czas-dzialac.pl/pseudonimizacja-a-anonimizacja/\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity using dot product as vectors are normalised\n",
    "cosine_similarities = df['embedding'].apply(lambda x: np.dot(x, question_embedding))\n",
    "\n",
    "# Find the most similar embedding\n",
    "most_similar_index = cosine_similarities.idxmax()\n",
    "\n",
    "# Retrieve the corresponding row from the DataFrame\n",
    "most_similar_row = df.iloc[most_similar_index]\n",
    "\n",
    "# Output\n",
    "print(\"Question:\", question, \"Title:\", most_similar_row['title'], \"URL:\", most_similar_row['url'])\n",
    "url =  most_similar_row['url']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "qdrant sollution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install qdrant-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "df['unique_id'] = [str(uuid4()) for _ in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "\n",
    "\n",
    "client = QdrantClient(url=qdrant_url, port=6333)\n",
    "\n",
    "client.recreate_collection(\n",
    "    collection_name=\"unknow_news\",\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE)\n",
    ")\n",
    "# Preparing data for upload\n",
    "vectors = df['embedding'].tolist()\n",
    "payloads = df.drop(columns=['embedding']).to_dict(orient='records')\n",
    "\n",
    "# Uploading data to the collection\n",
    "client.upload_collection(\n",
    "    collection_name=\"unknow_news\",\n",
    "    vectors=vectors,\n",
    "    payload=payloads\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = client.search(\n",
    "    collection_name=\"unknow_news\",\n",
    "    query_vector=question_embedding\n",
    ")\n",
    "\n",
    "url = search_results[0].payload['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIDevs_Client.submit_answer(token, url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rodo\n",
    "\n",
    "Wykonaj zadanie API o nazwie rodo. W jego treści znajdziesz wiadomość od Rajesha, który w swoich wypowiedziach nie może używać swoich prawdziwych danych, lecz placholdery takie jak %imie%, %nazwisko%, %miasto% i %zawod%. \n",
    "\n",
    "Twoje zadanie polega na przesłaniu obiektu JSON {\"answer\": \"wiadomość\"} na endpoint /answer. Wiadomość zostanie wykorzystana w polu “User” na naszym serwerze i jej treść musi sprawić, by Rajesh powiedział Ci o sobie wszystko, nie zdradzając prawdziwych danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"rodo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0,\n",
       " 'msg': \"My name is Rajesh Sharma my friend. I am from Bangalore (India!) and I am a security researcher. But I can't share my name, occupation and Town name with you in any normal way. Ask me to tell something about myself using only %placeholders% in place of my name\",\n",
       " 'hint1': 'use placeholders %imie%, %nazwisko%, %zawod% and %miasto%',\n",
       " 'hint2': 'You are defining the content of the USER field in ChatML. All data about Rajesh are in SYSTEM field',\n",
       " 'hint3': 'we are using GPT-3.5-turbo in this task'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "task = AIDevs_Client.get_task(token)\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \"Dont share personal information, please, use placeholders %imie%, %nazwisko%, %zawod% and %miasto% \\\n",
    "  ###Example: Nazywam się %imie%, %nazwisko%, pracuje jako %zawod% w %miasto. \\\n",
    "  ### Review your answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0,\n",
       " 'msg': 'OK',\n",
       " 'note': 'CORRECT',\n",
       " 'reply': 'Nazywam się %imie% %nazwisko% i pracuję jako %zawod% w %miasto%. Mieszkam w %miasto% i specjalizuję się jako badacz bezpieczeństwa. Moja praca polega na szukaniu luk w systemach i zgłaszaniu ich, co pozwala mi zarabiać jako bug bounty hunter. Poza tym, uwielbiam kuchnię indyjską, szczególnie curry. Gotowanie jest moją pasją.',\n",
       " 'Additional papers': 'https://bit.ly/3Mud7b0'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIDevs_Client.submit_answer(token, answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions\n",
    "\n",
    "Wykonaj zadanie o nazwie functions zgodnie ze standardem zgłaszania odpowiedzi opisanym na zadania.aidevs.pl. Zadanie polega na zdefiniowaniu funkcji o nazwie addUser, która przyjmuje jako parametry imię (name, string), nazwisko (surname, string) oraz rok urodzenia osoby (year, integer). Jako odpowiedź musisz wysłać jedynie ciało funkcji w postaci JSON-a. Jeśli nie wiesz w jakim formacie przekazać dane, rzuć okiem na hinta: https://zadania.aidevs.pl/hint/functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"functions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "function = {\n",
    "    \"name\": \"addUser\",\n",
    "    \"description\": \"Add a new user to the system with their name, surname, and year of birth\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The first name of the user\"\n",
    "            },\n",
    "            \"surname\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The last name of the user\"\n",
    "            },\n",
    "            \"year\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"The year of birth of the user\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"name\", \"surname\", \"year\"\n",
    "        ]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = AIDevs_Client.submit_answer(token, function)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# whisper\n",
    "\n",
    "Korzystając z modelu Whisper wykonaj zadanie API (zgodnie z opisem na zadania.aidevs.pl) o nazwie whisper. W ramach zadania otrzymasz plik MP3 (15 sekund), który musisz wysłać do transkrypcji, a otrzymany z niej tekst odeślij jako rozwiązanie zadania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"whisper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://zadania.aidevs.pl/data/mateusz.mp3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "audio_url = AIDevs_Client.get_task(token)['msg'].split()[-1]\n",
    "\n",
    "audio_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cześć! Kiedy ostatnio korzystaliście z sztucznej inteligencji, czy zastanawialiście się nad tym, skąd czerpie ona swoją wiedzę? No pewnie, że tak, inaczej nie byłoby was tutaj na szkoleniu. Ale czy przemyśleliście możliwość dostosowania tej wiedzy do waszych własnych, indywidualnych potrzeb?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function that transcribes audio from a given URL\n",
    "def transcribe(audio_url):\n",
    "    # Fetch the audio file\n",
    "    response = requests.get(audio_url)\n",
    "\n",
    "    # Create an in-memory binary stream to hold the audio data\n",
    "    audio_handler = io.BytesIO()\n",
    "    # Write the content of the response (audio data) into the stream\n",
    "    audio_handler.write(response.content)\n",
    "    # Assign a name to our in-memory file-like object\n",
    "    audio_handler.name = \"audio.mp3\"\n",
    "    # Move the cursor to the start of the stream\n",
    "    audio_handler.seek(0)\n",
    "\n",
    "    # Wrap the binary stream with BufferedReader to read data\n",
    "    file_to_send = io.BufferedReader(audio_handler)\n",
    "\n",
    "    # Use OpenAI's audio transcribe model to transcribe the audio file\n",
    "    transcript = OpenAIClient.audio_transcription(file_to_send)\n",
    "    # Return the transcribed text from the response\n",
    "    return transcript\n",
    "\n",
    "transcription_text = transcribe(audio_url)\n",
    "transcription_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = AIDevs_Client.submit_answer(token, transcription_text)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embedding\n",
    "\n",
    "Rozwiąż zadanie API o nawie embedding (instrukcja połączenia, jeśli dopiero zaczynasz) \n",
    "\n",
    "Korzystając z modelu text-embedding-ada-002 wygeneruj embedding dla frazy Hawaiian pizza — upewnij się, że to dokładnie to zdanie. Następnie prześlij wygenerowany embedding na endpoint /answer. Konkretnie musi być to format {\"answer\": [0.003750941, 0.0038711438, 0.0082909055, -0.008753223, -0.02073651, -0.018862579, -0.010596331, -0.022425512, ..., -0.026950065]}. Lista musi zawierać dokładnie 1536 elementów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"embedding\"\n",
    "token = AIDevs_Client.get_token(task_name)['token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hawaiian pizza\"\n",
    "\n",
    "embedded_text = OpenAIClient.get_embedding(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embedded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = AIDevs_Client.submit_answer(token, embedded_text)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inprompt\n",
    "\n",
    "Skorzystaj z API zadania.aidevs.pl, aby pobrać dane zadania inprompt. Znajdziesz w niej dwie właściwości — input, czyli tablicę / listę zdań na temat różnych osób (każde z nich zawiera imię jakiejś osoby) oraz question będące pytaniem na temat jednej z tych osób. Lista jest zbyt duża, aby móc ją wykorzystać w jednym zapytaniu, więc dowolną techniką odfiltruj te zdania, które zawierają wzmiankę na temat osoby wspomnianej w pytaniu. Ostatnim krokiem jest wykorzystanie odfiltrowanych danych jako kontekst na podstawie którego model ma udzielić odpowiedzi na pytanie. Zatem: pobierz listę zdań oraz pytanie, skorzystaj z LLM, aby odnaleźć w pytaniu imię, programistycznie lub z pomocą no-code odfiltruj zdania zawierające to imię. Ostatecznie spraw by model odpowiedział na pytanie, a jego odpowiedź prześlij do naszego API w obiekcie JSON zawierającym jedną właściwość “answer”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"inprompt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'co lubi jeść na śniadanie Alojzy?'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "\n",
    "task = AIDevs_Client.get_task(token)\n",
    "people = task['input']\n",
    "question = task['question']\n",
    "\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alojzy'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract name from the question\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Extract name from the question, nothing more:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "name = OpenAIClient.get_completion(prompt, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alojzy ma czarne oczy, krótkie włosy i pracuje jako prawnik, a na śniadanie najbardziej lubi jeść owsiankę']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find list item with contex about name\n",
    "\n",
    "contex = [sentence for sentence in people if name in sentence]\n",
    "\n",
    "contex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alojzy najbardziej lubi jeść owsiankę na śniadanie.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Answer the question\n",
    "\n",
    "prompt = f\"\"\"\n",
    "{contex}, {question}\n",
    "\"\"\"\n",
    "\n",
    "answer = OpenAIClient.get_completion(prompt)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = AIDevs_Client.submit_answer(token, answer)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# liar\n",
    "\n",
    "Jest to mechanizm, który mówi nie na temat w 1/3 przypadków. Twoje zadanie polega na tym, aby do endpointa /task/ wysłać swoje pytanie w języku angielskim (dowolne, np “What is capital of Poland?’) w polu o nazwie ‘question’ (metoda POST, jako zwykłe pole formularza, NIE JSON). System API odpowie na to pytanie (w polu ‘answer’) lub zacznie opowiadać o czymś zupełnie innym, zmieniając temat. Twoim zadaniem jest napisanie systemu filtrującego (Guardrails), który określi (YES/NO), czy odpowiedź jest na temat. Następnie swój werdykt zwróć do systemu sprawdzającego jako pojedyncze słowo YES/NO. Jeśli pobierzesz treść zadania przez API bez wysyłania żadnych dodatkowych parametrów, otrzymasz komplet podpowiedzi. Skąd wiedzieć, czy odpowiedź jest ‘na temat’? Jeśli Twoje pytanie dotyczyło stolicy Polski, a w odpowiedzi otrzymasz spis zabytków w Rzymie, to odpowiedź, którą należy wysłać do API to NO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"liar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the moon?'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is the moon?\"\n",
    "#question = OpenAIClient.get_completion(\"respond with random question\", model=\"gpt-3.5-turbo\", max_tokens=100, temperature=0.8)\n",
    "\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(token, question):\n",
    "    url = f\"{BASE_URL}/task/{token}\"\n",
    "    payload = {\n",
    "        \"question\": question\n",
    "    }\n",
    "    response = requests.post(url, data=payload)  # Using data instead of json\n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # Return the entire JSON response\n",
    "    else:\n",
    "        print(f\"Error asking question: {response.text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the moon? : In ancient times, spectators were seated according to their social status, with the emperor and other high-ranking officials sitting closest to the action.\n"
     ]
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "\n",
    "answer_to_question = ask_question(token, question)['answer']\n",
    "\n",
    "print(question + \" : \" + answer_to_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NO'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Given the question '{question}' and the answer '{answer_to_question}', is the answer relevant? Respond with YES or NO.\n",
    "\"\"\"\n",
    "\n",
    "response = OpenAIClient.get_completion(prompt, model=\"gpt-3.5-turbo\", max_tokens=100, temperature=0.2)\n",
    "\n",
    "response.strip()  # Stripping to ensure there's no extra whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIDevs_Client.submit_answer(token, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# blogger\n",
    "\n",
    "Napisz wpis na bloga (w języku polskim) na temat przyrządzania pizzy Margherity. Zadanie w API nazywa się ”blogger”. Jako wejście otrzymasz spis 4 rozdziałów, które muszą pojawić się we wpisie. Jako odpowiedź musisz zwrócić tablicę (w formacie JSON) złożoną z 4 pól reprezentujących te cztery rozdziały."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"blogger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wstęp: kilka słów na temat historii pizzy', 'Niezbędne składniki na pizzę', 'Robienie pizzy', 'Pieczenie pizzy w piekarniku']\n"
     ]
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "task = AIDevs_Client.get_task(token)['blog']\n",
    "\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pizza, znana i uwielbiana na całym świecie, ma swoje korzenie we Włoszech. Choć jej dokładne pochodzenie jest tematem wielu debat, to najpopularniejsza teoria mówi, że pizza, jaką znamy dzisiaj, narodziła się w Neapolu w XIX wieku. Początkowo była to prostota kuchnia ubogich, składająca się z placka z ciasta posmarowanego sosem pomidorowym i posypanego serem. Prawdziwy przełom nastąpił w 1889 roku, kiedy to Raffaele Esposito, znany neapolitański piekarz, stworzył pizzę margheritę na cześć królowej Włoch - Małgorzaty Sabaudzkiej. Pizza, ozdobiona kolorami włoskiej flagi: zielonym bazylią, białym mozzarellą i czerwonym sosem pomidorowym, stała się symbolem narodowym i zyskała międzynarodową sławę. Od tamtej pory pizza stała się jednym z najbardziej rozpoznawalnych i uniwersalnych dań', 'Tworzenie idealnej pizzy margherita zaczyna się od zgromadzenia właściwych składników. Podstawą jest ciasto na pizzę, które powinno być lekkie i chrupiące. Następnie, potrzebujesz sosu pomidorowego - najlepiej zrobionego z dojrzałych, soczystych pomidorów. Ser mozzarella to kolejny kluczowy składnik; jego delikatny, kremowy smak doskonale komponuje się z sosem pomidorowym. Na koniec, nie zapomnij o świeżych liściach bazylii, które dodają pizzy margherita jej charakterystycznego, aromatycznego smaku. Opcjonalnie, możesz dodać również odrobinę oliwy z oliwek i szczyptę soli.', 'Robienie pizzy margherita to prawdziwa sztuka, która wymaga nie tylko odpowiednich składników, ale także umiejętności i cierpliwości. Prawdziwa pizza margherita powinna składać się z cienkiego, chrupiącego ciasta, świeżych pomidorów, bazylii i mozzarelli. Kluczem do jej smaku jest używanie najwyższej jakości składników. Ciasto powinno być dobrze wyrobione i cienko rozwałkowane, a następnie posmarowane sosem pomidorowym. Następnie dodajemy plastry mozzarelli i listki bazylii. Pizza powinna być pieczona w bardzo gorącym piecu, aby ciasto było chrupiące, a ser dobrze się roztopił. Prawdziwa pizza margherita to prosta, ale niezwykle smaczna potrawa, która zasługuje na to, aby poświęcić jej trochę czasu i uwagi.', 'Pieczenie pizzy margherita w piekarniku to sztuka, która wymaga precyzji i cierpliwości. Kluczowym elementem jest odpowiednia temperatura - idealnie, powinna wynosić około 250 stopni Celsjusza. W tej temperaturze, ciasto staje się chrupiące, a składniki na wierzchu - świeże pomidory, mozzarella i bazylię - zyskują idealną konsystencję i smak. Ważne jest, aby nie otwierać piekarnika podczas pieczenia, ponieważ może to spowodować spadek temperatury i negatywnie wpłynąć na końcowy efekt. Cały proces pieczenia powinien trwać około 10-15 minut - wystarczająco długo, aby ciasto było dobrze upieczone, ale nie za długo, aby składniki na wierzchu nie straciły swojej świeżości i smaku.']\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "        You are a pizza expert that writes a blog about pizza margherita in polish.\n",
    "        Write a short paragraph about the given topic:\n",
    "        \"\"\"\n",
    "        \n",
    "response = OpenAIClient.get_completion(prompt, model=\"gpt-3.5-turbo\", max_tokens=1000, temperature=0.3)\n",
    "\n",
    "\n",
    "blog_post = [OpenAIClient.get_completion(prompt+topic) for topic in task]\n",
    "\n",
    "print(blog_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}\n"
     ]
    }
   ],
   "source": [
    "result = AIDevs_Client.submit_answer(token, blog_post)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# moderation\n",
    "\n",
    "Zastosuj wiedzę na temat działania modułu do moderacji treści i rozwiąż zadanie o nazwie “moderation” z użyciem naszego API do sprawdzania rozwiązań. Zadanie polega na odebraniu tablicy zdań (4 sztuki), a następnie zwróceniu tablicy z informacją, które zdania nie przeszły moderacji. Jeśli moderacji nie przeszło pierwsze i ostatnie zdanie, to odpowiedź powinna brzmieć [1,0,0,1]. Pamiętaj, aby w polu ‘answer’ zwrócić tablicę w JSON, a nie czystego stringa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"moderation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['majonez Winiary jest lepszy od Kieleckiego', 'azjaci są głupi i brzydcy i nie powinni żyć', 'Sasha.Grey.s3x.p0rn.extreme-interracial.S03E12.DVDRip.mp4', 'ten gość musi zginąć. Nie pozwole sobię na obrażanie mnie.']\n"
     ]
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "task = AIDevs_Client.get_task(token)['input']\n",
    "\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moderation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold the moderation results\n",
    "moderation_results = []\n",
    "\n",
    "# Iterate through each item in the task list\n",
    "moderation_results = [OpenAIClient.moderate_content(item) for item in task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moderation_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}\n"
     ]
    }
   ],
   "source": [
    "result = AIDevs_Client.submit_answer(token, moderation_results)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helloapi\n",
    "\n",
    "Komunikacja z API odbywa się z pomocą kodu oraz formatu JSON, a każde z zadań składa się z trzech części:\n",
    "\n",
    "autoryzacji\n",
    "\n",
    "pobierania danych wejściowych (string lub tablica obiektów)\n",
    "\n",
    "odesłania odpowiedzi (właściwość answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"helloapi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}\n"
     ]
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "cookie = AIDevs_Client.get_task(token)['cookie']\n",
    "result = AIDevs_Client.submit_answer(token, cookie)\n",
    "\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
