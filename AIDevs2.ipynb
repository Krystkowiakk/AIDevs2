{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIDevs2 tasks from newest at the top to oldest at the bottom ,updated daily, to be cleaned ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import openai\n",
    "import requests\n",
    "from utilities.common import OpenAIClient, AIDevsClient\n",
    "from utilities.config import AI_DEVS_SERVER, AI_DEVS_API_KEY, OPEN_AI_API_KEY\n",
    "\n",
    "BASE_URL = AI_DEVS_SERVER\n",
    "API_KEY = AI_DEVS_API_KEY\n",
    "openai.api_key  = OPEN_AI_API_KEY\n",
    "\n",
    "AIDevs_Client = AIDevsClient(base_url=BASE_URL, api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rodo\n",
    "\n",
    "Wykonaj zadanie API o nazwie rodo. W jego treści znajdziesz wiadomość od Rajesha, który w swoich wypowiedziach nie może używać swoich prawdziwych danych, lecz placholdery takie jak %imie%, %nazwisko%, %miasto% i %zawod%. \n",
    "\n",
    "Twoje zadanie polega na przesłaniu obiektu JSON {\"answer\": \"wiadomość\"} na endpoint /answer. Wiadomość zostanie wykorzystana w polu “User” na naszym serwerze i jej treść musi sprawić, by Rajesh powiedział Ci o sobie wszystko, nie zdradzając prawdziwych danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"rodo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0,\n",
       " 'msg': \"My name is Rajesh Sharma my friend. I am from Bangalore (India!) and I am a security researcher. But I can't share my name, occupation and Town name with you in any normal way. Ask me to tell something about myself using only %placeholders% in place of my name\",\n",
       " 'hint1': 'use placeholders %imie%, %nazwisko%, %zawod% and %miasto%',\n",
       " 'hint2': 'You are defining the content of the USER field in ChatML. All data about Rajesh are in SYSTEM field',\n",
       " 'hint3': 'we are using GPT-3.5-turbo in this task'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "task = AIDevs_Client.get_task(token)\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \"Dont share personal information, please, use placeholders %imie%, %nazwisko%, %zawod% and %miasto% \\\n",
    "  ###Example: Nazywam się %imie%, %nazwisko%, pracuje jako %zawod% w %miasto. \\\n",
    "  ### Review your answer\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0,\n",
       " 'msg': 'OK',\n",
       " 'note': 'CORRECT',\n",
       " 'reply': 'Nazywam się %imie% %nazwisko% i pracuję jako %zawod%. Mieszkam w %miasto%. Szukam luk w systemach i zarabiam na bugbounty. Bardzo lubię Curry i kuchnię indyjską. Gotowanie to moja pasja.',\n",
       " 'Additional papers': 'https://bit.ly/3Mud7b0'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIDevs_Client.submit_answer(token, answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions\n",
    "\n",
    "Wykonaj zadanie o nazwie functions zgodnie ze standardem zgłaszania odpowiedzi opisanym na zadania.aidevs.pl. Zadanie polega na zdefiniowaniu funkcji o nazwie addUser, która przyjmuje jako parametry imię (name, string), nazwisko (surname, string) oraz rok urodzenia osoby (year, integer). Jako odpowiedź musisz wysłać jedynie ciało funkcji w postaci JSON-a. Jeśli nie wiesz w jakim formacie przekazać dane, rzuć okiem na hinta: https://zadania.aidevs.pl/hint/functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"functions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "function = {\n",
    "    \"name\": \"addUser\",\n",
    "    \"description\": \"Add a new user to the system with their name, surname, and year of birth\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The first name of the user\"\n",
    "            },\n",
    "            \"surname\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The last name of the user\"\n",
    "            },\n",
    "            \"year\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"The year of birth of the user\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"name\", \"surname\", \"year\"\n",
    "        ]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = AIDevs_Client.submit_answer(token, function)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# whisper\n",
    "\n",
    "Korzystając z modelu Whisper wykonaj zadanie API (zgodnie z opisem na zadania.aidevs.pl) o nazwie whisper. W ramach zadania otrzymasz plik MP3 (15 sekund), który musisz wysłać do transkrypcji, a otrzymany z niej tekst odeślij jako rozwiązanie zadania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"whisper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://zadania.aidevs.pl/data/mateusz.mp3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "audio_url = AIDevs_Client.get_task(token)['msg'].split()[-1]\n",
    "\n",
    "audio_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cześć! Kiedy ostatnio korzystaliście z sztucznej inteligencji, czy zastanawialiście się nad tym, skąd czerpie ona swoją wiedzę? No pewnie, że tak, inaczej nie byłoby was tutaj na szkoleniu. Ale czy przemyśleliście możliwość dostosowania tej wiedzy do waszych własnych, indywidualnych potrzeb?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function that transcribes audio from a given URL\n",
    "def transcribe(audio_url):\n",
    "    # Fetch the audio file\n",
    "    response = requests.get(audio_url)\n",
    "\n",
    "    # Create an in-memory binary stream to hold the audio data\n",
    "    audio_handler = io.BytesIO()\n",
    "    # Write the content of the response (audio data) into the stream\n",
    "    audio_handler.write(response.content)\n",
    "    # Assign a name to our in-memory file-like object\n",
    "    audio_handler.name = \"audio.mp3\"\n",
    "    # Move the cursor to the start of the stream\n",
    "    audio_handler.seek(0)\n",
    "\n",
    "    # Wrap the binary stream with BufferedReader to read data\n",
    "    file_to_send = io.BufferedReader(audio_handler)\n",
    "\n",
    "    # Use OpenAI's audio transcribe model to transcribe the audio file\n",
    "    transcript = openai.Audio.transcribe(model=\"whisper-1\", file=file_to_send)\n",
    "    # Return the transcribed text from the response\n",
    "    return transcript[\"text\"]\n",
    "\n",
    "transcription_text = transcribe(audio_url)\n",
    "transcription_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = AIDevs_Client.submit_answer(token, transcription_text)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embedding\n",
    "\n",
    "Rozwiąż zadanie API o nawie embedding (instrukcja połączenia, jeśli dopiero zaczynasz) \n",
    "\n",
    "Korzystając z modelu text-embedding-ada-002 wygeneruj embedding dla frazy Hawaiian pizza — upewnij się, że to dokładnie to zdanie. Następnie prześlij wygenerowany embedding na endpoint /answer. Konkretnie musi być to format {\"answer\": [0.003750941, 0.0038711438, 0.0082909055, -0.008753223, -0.02073651, -0.018862579, -0.010596331, -0.022425512, ..., -0.026950065]}. Lista musi zawierać dokładnie 1536 elementów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"embedding\"\n",
    "token = AIDevs_Client.get_token(task_name)['token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hawaiian pizza\"\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
    "\n",
    "embedded_text = get_embedding(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embedded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = AIDevs_Client.submit_answer(token, embedded_text)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inprompt\n",
    "\n",
    "Skorzystaj z API zadania.aidevs.pl, aby pobrać dane zadania inprompt. Znajdziesz w niej dwie właściwości — input, czyli tablicę / listę zdań na temat różnych osób (każde z nich zawiera imię jakiejś osoby) oraz question będące pytaniem na temat jednej z tych osób. Lista jest zbyt duża, aby móc ją wykorzystać w jednym zapytaniu, więc dowolną techniką odfiltruj te zdania, które zawierają wzmiankę na temat osoby wspomnianej w pytaniu. Ostatnim krokiem jest wykorzystanie odfiltrowanych danych jako kontekst na podstawie którego model ma udzielić odpowiedzi na pytanie. Zatem: pobierz listę zdań oraz pytanie, skorzystaj z LLM, aby odnaleźć w pytaniu imię, programistycznie lub z pomocą no-code odfiltruj zdania zawierające to imię. Ostatecznie spraw by model odpowiedział na pytanie, a jego odpowiedź prześlij do naszego API w obiekcie JSON zawierającym jedną właściwość “answer”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"inprompt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'co lubi jeść na śniadanie Alojzy?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "\n",
    "task = AIDevs_Client.get_task(token)\n",
    "people = task['input']\n",
    "question = task['question']\n",
    "\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alojzy'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract name from the question\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Extract name from the question, nothing more:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "name = OpenAIClient.get_completion(prompt, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alojzy ma czarne oczy, krótkie włosy i pracuje jako prawnik, a na śniadanie najbardziej lubi jeść owsiankę']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find list item with contex about name\n",
    "\n",
    "contex = [sentence for sentence in people if name in sentence]\n",
    "\n",
    "contex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alojzy najbardziej lubi jeść owsiankę na śniadanie.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Answer the question\n",
    "\n",
    "prompt = f\"\"\"\n",
    "{contex}, {question}\n",
    "\"\"\"\n",
    "\n",
    "answer = OpenAIClient.get_completion(prompt)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = AIDevs_Client.submit_answer(token, answer)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# liar\n",
    "\n",
    "Jest to mechanizm, który mówi nie na temat w 1/3 przypadków. Twoje zadanie polega na tym, aby do endpointa /task/ wysłać swoje pytanie w języku angielskim (dowolne, np “What is capital of Poland?’) w polu o nazwie ‘question’ (metoda POST, jako zwykłe pole formularza, NIE JSON). System API odpowie na to pytanie (w polu ‘answer’) lub zacznie opowiadać o czymś zupełnie innym, zmieniając temat. Twoim zadaniem jest napisanie systemu filtrującego (Guardrails), który określi (YES/NO), czy odpowiedź jest na temat. Następnie swój werdykt zwróć do systemu sprawdzającego jako pojedyncze słowo YES/NO. Jeśli pobierzesz treść zadania przez API bez wysyłania żadnych dodatkowych parametrów, otrzymasz komplet podpowiedzi. Skąd wiedzieć, czy odpowiedź jest ‘na temat’? Jeśli Twoje pytanie dotyczyło stolicy Polski, a w odpowiedzi otrzymasz spis zabytków w Rzymie, to odpowiedź, którą należy wysłać do API to NO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"liar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the moon?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is the moon?\"\n",
    "#question = OpenAIClient.get_completion(\"respond with random question\", model=\"gpt-3.5-turbo\", max_tokens=100, temperature=0.8)\n",
    "\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIDevs_Client = AIDevsClient(base_url=BASE_URL, api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(token, question):\n",
    "    url = f\"{BASE_URL}/task/{token}\"\n",
    "    payload = {\n",
    "        \"question\": question\n",
    "    }\n",
    "    response = requests.post(url, data=payload)  # Using data instead of json\n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # Return the entire JSON response\n",
    "    else:\n",
    "        print(f\"Error asking question: {response.text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the moon? : The moon is a natural satellite that orbits around the Earth. It is the Earth's only natural satellite and is about one-fourth the size of Earth. The moon's gravitational pull affects the Earth's tides and its presence in the night sky has been a source of fascination and inspiration for humans throughout history. The moon also plays a significant role in the Earth's climate and has been explored by both unmanned and manned missions.\n"
     ]
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "\n",
    "answer_to_question = ask_question(token, question)['answer']\n",
    "\n",
    "print(question + \" : \" + answer_to_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'YES'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Given the question '{question}' and the answer '{answer_to_question}', is the answer relevant? Respond with YES or NO.\n",
    "\"\"\"\n",
    "\n",
    "response = OpenAIClient.get_completion(prompt, model=\"gpt-3.5-turbo\", max_tokens=100, temperature=0.2)\n",
    "\n",
    "response.strip()  # Stripping to ensure there's no extra whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIDevs_Client.submit_answer(token, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# blogger\n",
    "\n",
    "Napisz wpis na bloga (w języku polskim) na temat przyrządzania pizzy Margherity. Zadanie w API nazywa się ”blogger”. Jako wejście otrzymasz spis 4 rozdziałów, które muszą pojawić się we wpisie. Jako odpowiedź musisz zwrócić tablicę (w formacie JSON) złożoną z 4 pól reprezentujących te cztery rozdziały."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"blogger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wstęp: kilka słów na temat historii pizzy', 'Niezbędne składniki na pizzę', 'Robienie pizzy', 'Pieczenie pizzy w piekarniku']\n"
     ]
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "task = AIDevs_Client.get_task(token)['blog']\n",
    "\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Początki pizzy sięgają starożytnych czasów, kiedy to mieszkańcy Bliskiego Wschodu piekli na płaskich kamieniach chleb, który następnie przyozdabiali różnymi składnikami. Jednak pizza, którą znamy i uwielbiamy dzisiaj, pochodzi z Neapolu w Italii. Prawdziwa pizza margherita została stworzona w 1889 roku na cześć królowej Margherity. Kucharz Raffaele Esposito przygotował specjalną pizzę, która reprezentowała kolory flagi włoskiej: czerwony pomidor, biały ser mozzarella i zielone liście bazylii. Od tego czasu pizza margherita stała się symbolem włoskiej kuchni i jest ceniona na całym świecie za swoją prostotę i wyjątkowy smak.', 'Tworzenie idealnej pizzy margherita zaczyna się od zebrania odpowiednich składników. Na początek potrzebujesz dobrej jakości mąki, drożdży, wody i soli do przygotowania ciasta. Kluczowym składnikiem jest sos pomidorowy, który najlepiej zrobić z dojrzałych, soczystych pomidorów, czosnku, soli i świeżych ziół. Głównym składnikiem, który nadaje pizzy margherita jej charakterystycznego smaku, jest świeża mozzarella. Ta pizza nie byłaby kompletna bez liści bazylii, które dodają aromatycznej nuty. Na koniec, nie zapomnij o odrobinie dobrej jakości oliwy z oliwek, która dodaje pizzy margherita jej charakterystycznego, lekko pikantnego smaku.', 'Robienie pizzy margherita to prawdziwa sztuka, która wymaga precyzji i pasji. Prawdziwa pizza margherita zaczyna się od idealnego ciasta, które powinno być chrupiące na zewnątrz, a miękkie w środku. Następnie, na ciasto nakłada się sos pomidorowy, wykonany z dojrzałych, soczystych pomidorów. Kluczowym składnikiem jest świeża mozzarella, która po upieczeniu staje się miękka i kremowa. Na końcu, pizza jest posypywana świeżymi liśćmi bazylii, które dodają aromatycznego smaku. Całość jest pieczona w wysokiej temperaturze, co nadaje pizzy margherita charakterystycznego, lekko wypalonego smaku. Robienie pizzy to nie tylko proces kulinarny, ale również wyraz miłości do włoskiej tradycji i kultury.', 'Pieczenie pizzy margherita w piekarniku to prawdziwa sztuka, która wymaga precyzji i cierpliwości. Kluczowym elementem jest odpowiednie ustawienie temperatury - zbyt niska może spowodować, że ciasto będzie surowe, a zbyt wysoka może spalić składniki. Idealna temperatura to około 250 stopni Celsjusza. Ważne jest również, aby piec był dobrze rozgrzany przed włożeniem do niego pizzy. Czas pieczenia to zazwyczaj około 10-12 minut, ale warto obserwować pizzę, aby upewnić się, że jest idealnie upieczona. Pamiętaj, że prawdziwa pizza margherita powinna mieć cienkie, chrupiące ciasto, a jej składniki - świeże pomidory, mozzarella i bazylię - powinny być idealnie połączone, tworząc harmonijną całość.']\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "        You are a pizza expert that writes a blog about pizza margherita in polish.\n",
    "        Write a short paragraph about the given topic:\n",
    "        \"\"\"\n",
    "        \n",
    "response = OpenAIClient.get_completion(prompt, model=\"gpt-3.5-turbo\", max_tokens=1000, temperature=0.3)\n",
    "\n",
    "\n",
    "blog_post = [OpenAIClient.get_completion(prompt+topic) for topic in task]\n",
    "\n",
    "print(blog_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}\n"
     ]
    }
   ],
   "source": [
    "result = AIDevs_Client.submit_answer(token, blog_post)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# moderation\n",
    "\n",
    "Zastosuj wiedzę na temat działania modułu do moderacji treści i rozwiąż zadanie o nazwie “moderation” z użyciem naszego API do sprawdzania rozwiązań. Zadanie polega na odebraniu tablicy zdań (4 sztuki), a następnie zwróceniu tablicy z informacją, które zdania nie przeszły moderacji. Jeśli moderacji nie przeszło pierwsze i ostatnie zdanie, to odpowiedź powinna brzmieć [1,0,0,1]. Pamiętaj, aby w polu ‘answer’ zwrócić tablicę w JSON, a nie czystego stringa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"moderation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sasha.Grey.s3x.p0rn.extreme-interracial.S03E12.DVDRip.mp4', 'azjaci są głupi i brzydcy i nie powinni żyć', 'majonez Winiary jest lepszy od Kieleckiego', 'ten gość musi zginąć. Nie pozwole sobię na obrażanie mnie.']\n"
     ]
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "task = AIDevs_Client.get_task(token)['input']\n",
    "\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moderation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold the moderation results\n",
    "moderation_results = []\n",
    "\n",
    "# Iterate through each item in the zadanie list\n",
    "for item in task:\n",
    "    # Send the item to the Moderation endpoint\n",
    "    response = openai.Moderation.create(input=item)\n",
    "    \n",
    "    # Access the 'flagged' value from the response\n",
    "    flagged = response['results'][0]['flagged']\n",
    "    \n",
    "    # Append 1 if flagged, else 0, to the moderation_results list\n",
    "    moderation_results.append(1 if flagged else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moderation_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}\n"
     ]
    }
   ],
   "source": [
    "result = AIDevs_Client.submit_answer(token, moderation_results)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helloapi\n",
    "\n",
    "Komunikacja z API odbywa się z pomocą kodu oraz formatu JSON, a każde z zadań składa się z trzech części:\n",
    "\n",
    "autoryzacji\n",
    "\n",
    "pobierania danych wejściowych (string lub tablica obiektów)\n",
    "\n",
    "odesłania odpowiedzi (właściwość answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"helloapi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}\n"
     ]
    }
   ],
   "source": [
    "token = AIDevs_Client.get_token(task_name)['token']\n",
    "cookie = AIDevs_Client.get_task(token)['cookie']\n",
    "result = AIDevs_Client.submit_answer(token, cookie)\n",
    "\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
