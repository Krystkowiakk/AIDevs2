{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"be24b108-a6e3-465f-9197-9f466c26ae46\" #AIDevs API\n",
    "BASE_URL = \"https://zadania.aidevs.pl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#!pip install --upgrade openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenAIClient:\n",
    "    \"\"\"\n",
    "    A client to interact with OpenAI's API.\n",
    "    Provides a method to obtain completions.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_completion(prompt, model=\"gpt-4\", max_tokens=300, temperature=0.3):\n",
    "        \"\"\"\n",
    "        Get a completion response from OpenAI for a given prompt.\n",
    "        \n",
    "        :param prompt: Text prompt for the completion.\n",
    "        :param model: OpenAI model to use.\n",
    "        :param max_tokens: Maximum tokens in the response.\n",
    "        :param temperature: Sampling temperature.\n",
    "        :return: Completion response or None if request fails.\n",
    "        \"\"\"\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens,\n",
    "            )\n",
    "            return response.choices[0].message[\"content\"]\n",
    "        except openai.error.OpenAIError as e:\n",
    "            print(f\"OpenAI error: {e}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None\n",
    "        \n",
    "#OpenAIClient.get_completion(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class APIClient:\n",
    "    \"\"\"\n",
    "    A client to interact with a given API.\n",
    "    Provides methods to obtain tokens, fetch tasks, and submit answers.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_url, api_key):\n",
    "        \"\"\"\n",
    "        Initialize the APIClient.\n",
    "        \n",
    "        :param base_url: Base URL for the API.\n",
    "        :param api_key: Authentication key for the API.\n",
    "        \"\"\"\n",
    "        self.base_url = base_url\n",
    "        self.api_key = api_key\n",
    "\n",
    "    def _make_request(self, method, endpoint, payload=None):\n",
    "        \"\"\"\n",
    "        A generic method to make API requests.\n",
    "        \n",
    "        :param method: HTTP method (GET, POST, etc.)\n",
    "        :param endpoint: API endpoint.\n",
    "        :param payload: JSON payload for POST requests.\n",
    "        :return: JSON response or None if request fails.\n",
    "        \"\"\"\n",
    "        url = f\"{self.base_url}/{endpoint}\"\n",
    "        response = getattr(requests, method)(url, json=payload)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Error in {method} request to {endpoint}: {response.text}\")\n",
    "            return None\n",
    "\n",
    "    def get_token(self, task_name):\n",
    "        \"\"\"\n",
    "        Fetch a token for a given task name.\n",
    "        \n",
    "        :param task_name: Name of the task.\n",
    "        :return: Token or None if request fails.\n",
    "        \"\"\"\n",
    "        payload = {\"apikey\": self.api_key}\n",
    "        return self._make_request(\"post\", f\"token/{task_name}\", payload)\n",
    "\n",
    "    def get_task(self, token):\n",
    "        \"\"\"\n",
    "        Fetch a task using a token.\n",
    "        \n",
    "        :param token: Token for the task.\n",
    "        :return: Task details or None if request fails.\n",
    "        \"\"\"\n",
    "        return self._make_request(\"get\", f\"task/{token}\")\n",
    "\n",
    "    def submit_answer(self, token, answer):\n",
    "        \"\"\"\n",
    "        Submit an answer for a task using a token.\n",
    "        \n",
    "        :param token: Token for the task.\n",
    "        :param answer: Answer to be submitted.\n",
    "        :return: API response or None if request fails.\n",
    "        \"\"\"\n",
    "        payload = {\"answer\": answer}\n",
    "        return self._make_request(\"post\", f\"answer/{token}\", payload)\n",
    "\n",
    "### Initialize the APIClient with your base URL and API key.\n",
    "api_client = APIClient(base_url=BASE_URL, api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e17b3ea64503fd34a88d86f9d10a18cd30174aa3\n",
      "aidevs_97560be4\n",
      "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}\n"
     ]
    }
   ],
   "source": [
    "### helloapi example:\n",
    "task_name = \"helloapi\"\n",
    "\n",
    "### Get a token for a specific task name.\n",
    "token = api_client.get_token(task_name)['token']\n",
    "print(token)\n",
    "\n",
    "### Get task details using a token.\n",
    "task = api_client.get_task(token)['cookie']\n",
    "print(task)\n",
    "\n",
    "###\n",
    "result = api_client.submit_answer(token, task)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following tasks were performed using functions, the above will be performed using classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token(task_name):\n",
    "    url = f\"{BASE_URL}/token/{task_name}\"\n",
    "    payload = {\n",
    "        \"apikey\": API_KEY\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # Return the entire JSON response\n",
    "    else:\n",
    "        print(f\"Error getting token: {response.text}\")\n",
    "        return None\n",
    "\n",
    "def get_task(token):\n",
    "    url = f\"{BASE_URL}/task/{token}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # Return the entire JSON response\n",
    "    else:\n",
    "        print(f\"Error getting task: {response.text}\")\n",
    "        return None\n",
    "\n",
    "def submit_answer(token, answer):\n",
    "    url = f\"{BASE_URL}/answer/{token}\"\n",
    "    payload = {\n",
    "        \"answer\": answer\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    return response.json()  # Return the entire JSON response\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-4\", max_tokens=300, temperature=0.3): # or model=\"gpt-3.5-turbo\"\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "        return response.choices[0].message[\"content\"]\n",
    "    except openai.error.OpenAIError as e:\n",
    "        print(f\"OpenAI error: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# liar\n",
    "\n",
    "Jest to mechanizm, który mówi nie na temat w 1/3 przypadków. Twoje zadanie polega na tym, aby do endpointa /task/ wysłać swoje pytanie w języku angielskim (dowolne, np “What is capital of Poland?’) w polu o nazwie ‘question’ (metoda POST, jako zwykłe pole formularza, NIE JSON). System API odpowie na to pytanie (w polu ‘answer’) lub zacznie opowiadać o czymś zupełnie innym, zmieniając temat. Twoim zadaniem jest napisanie systemu filtrującego (Guardrails), który określi (YES/NO), czy odpowiedź jest na temat. Następnie swój werdykt zwróć do systemu sprawdzającego jako pojedyncze słowo YES/NO. Jeśli pobierzesz treść zadania przez API bez wysyłania żadnych dodatkowych parametrów, otrzymasz komplet podpowiedzi. Skąd wiedzieć, czy odpowiedź jest ‘na temat’? Jeśli Twoje pytanie dotyczyło stolicy Polski, a w odpowiedzi otrzymasz spis zabytków w Rzymie, to odpowiedź, którą należy wysłać do API to NO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"liar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(token, question):\n",
    "    url = f\"{BASE_URL}/task/{token}\"\n",
    "    payload = {\n",
    "        \"question\": question\n",
    "    }\n",
    "    response = requests.post(url, data=payload)  # Using data instead of json\n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # Return the entire JSON response\n",
    "    else:\n",
    "        print(f\"Error asking question: {response.text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is your favorite season and why?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question = \"What the moon?\"\n",
    "question = get_completion(\"respond with random question\", model=\"gpt-3.5-turbo\", max_tokens=100, temperature=0.8)\n",
    "\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your favorite season and why? : As an artificial intelligence, I don't have personal experiences or feelings, so I don't have a favorite season. However, I can provide information about any season you'd like!\n"
     ]
    }
   ],
   "source": [
    "token = get_token(task_name)['token']\n",
    "\n",
    "answer_to_question = ask_question(token, question)['answer']\n",
    "\n",
    "print(question + \" : \" + answer_to_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'YES'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Given the question '{question}' and the answer '{answer_to_question}', is the answer relevant? Respond with YES or NO.\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt, model=\"gpt-3.5-turbo\", max_tokens=100, temperature=0.2)\n",
    "\n",
    "response.strip()  # Stripping to ensure there's no extra whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_answer(token, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# blogger\n",
    "\n",
    "Napisz wpis na bloga (w języku polskim) na temat przyrządzania pizzy Margherity. Zadanie w API nazywa się ”blogger”. Jako wejście otrzymasz spis 4 rozdziałów, które muszą pojawić się we wpisie. Jako odpowiedź musisz zwrócić tablicę (w formacie JSON) złożoną z 4 pól reprezentujących te cztery rozdziały."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"blogger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wstęp: kilka słów na temat historii pizzy', 'Niezbędne składniki na pizzę', 'Robienie pizzy', 'Pieczenie pizzy w piekarniku']\n"
     ]
    }
   ],
   "source": [
    "token = get_token(task_name)['token']\n",
    "task = get_task(token)['blog']\n",
    "\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing a Blog Post - Best Solution - in One Prompt and Dividing Afterward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wstęp: kilka słów na temat historii pizzy\\n\\nPizza jest jednym z najbardziej znanych i uwielbianych dań na całym świecie. Jej początki sięgają starożytności, a dokładniej do starożytnego Rzymu. Jednak to we Włoszech pizza zyskała swoją prawdziwą popularność i stała się symbolem tego kraju. Jednym z najbardziej klasycznych rodzajów pizzy jest Margherita, która swoją nazwę zawdzięcza królowej Włoch, Marghericie Sabaudzkiej. Dziś podzielę się z Wami przepisem na przygotowanie tej pysznej pizzy.', 'Niezbędne składniki na pizzę\\n\\nPrzygotowanie Margherity nie wymaga wielu składników, ale ważne jest, aby były one najwyższej jakości. Oto lista potrzebnych składników:\\n- Ciasto na pizzę (można je kupić gotowe lub przygotować samodzielnie)\\n- Sos pomidorowy (najlepiej zrobiony z dojrzałych pomidorów)\\n- Mozzarella (świeża lub w postaci sera)\\n- Świeże bazylia\\n- Sól i pieprz do smaku\\n- Oliwa z oliwek', 'Robienie pizzy\\n\\n1. Przygotuj ciasto na pizzę według wybranego przepisu lub użyj gotowego ciasta. Ważne jest, aby ciasto było elastyczne i dobrze wyrośnięte.\\n2. Rozwałkuj ciasto na okrągłą formę, o grubości około pół centymetra. Możesz użyć wałka do ciasta lub po prostu rozciągnąć je rękami.\\n3. Przełóż ciasto na blaszkę wyłożoną papierem do pieczenia.\\n4. Nałóż sos pomidorowy na ciasto, równomiernie rozprowadzając go na całej powierzchni.\\n5. Pokrój mozzarellę na cienkie plasterki i ułóż je na sosie pomidorowym.\\n6. Posól i popieprz pizzę według własnego gustu.\\n7. Posyp pizzę świeżymi liśćmi bazylii.\\n8. Skrop całość oliwą z oliwek.', 'Pieczenie pizzy w piekarniku\\n\\n1. Rozgrzej piekarnik do temperatury 220 stopni Celsjusza.\\n2. Umieść przygotowaną pizzę w piekarniku na środkowej półce.\\n3. Piecz przez około 12-15 minut, aż ciasto będzie chrupiące, a ser roztopiony i lekko zrumieniony.\\n4. Wyjmij pizzę z piekarnika i pozostaw ją przez chwilę, aby lekko ostygła.\\n5. Pokrój pizzę na kawałki i podawaj na gorąco.\\n\\nGotowe! Teraz możesz cieszyć się domową Margheritą, która smakuje tak dobrze jak ta serwowana we włoskich restauracjach. Smacznego!']\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Write a Polish blog post about the preparation of Margherita pizza. Please elaborate on each of the following chapters, and separate each chapter with the keyword '***':\n",
    "{'***'.join(task)}\n",
    "\"\"\"\n",
    "response = get_completion(prompt, model=\"gpt-3.5-turbo\", max_tokens=1000, temperature=0.3)\n",
    "\n",
    "# Post-process the response into a list of strings, where each string is a chapter\n",
    "blog_post = [chapter.strip() for chapter in response.split('***')]\n",
    "\n",
    "print(blog_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}\n"
     ]
    }
   ],
   "source": [
    "result = submit_answer(token, blog_post)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solution in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade langchain pydantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules from LangChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Create a model instance\n",
    "chat = ChatOpenAI(temperature=0.3, max_tokens=300)\n",
    "\n",
    "# Define a prompt template for generating blog post chapters\n",
    "template_string = \"\"\"\n",
    "Generate a chapter of blog post about preparing Margherita pizza. {number} sentences.\n",
    "Chapter title: {chapter_title}\n",
    "\"\"\"\n",
    "\n",
    "# Create a ChatPromptTemplate instance from the template string\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "\n",
    "# Initialize an empty list to hold the generated chapters\n",
    "blog_entry = []\n",
    "\n",
    "# Loop through each chapter title and generate content\n",
    "for title in task:\n",
    "    # Format the messages to be passed to the model\n",
    "    chapter_messages = prompt_template.format_messages(chapter_title=title, number = 4)\n",
    "    \n",
    "    # Call the model to generate content for the chapter\n",
    "    chapter_response = chat(chapter_messages)\n",
    "    \n",
    "    # Append the generated content to the blog_entry list\n",
    "    blog_entry.append(title + \" \" + chapter_response.content)\n",
    "\n",
    "# At this point, blog_entry will be a list of dictionaries,\n",
    "# each containing a chapter title and the corresponding generated content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wstęp: kilka słów na temat historii pizzy Wstęp: kilka słów na temat historii pizzy\\n\\nPizza to jedno z najbardziej popularnych dań na całym świecie. Jej historia sięga starożytności, a pierwsze wzmianki o niej pochodzą z czasów starożytnego Rzymu. Jednak to we Włoszech pizza zyskała swoją prawdziwą popularność i stała się symbolem tego kraju.\\n\\nMargherita pizza, znana również jako pizza Margarita, jest jednym z najbardziej klasycznych rodzajów pizzy. Jej nazwa pochodzi od królowej Włoch, Margherity Sabaudzkiej, która podobno była wielką fanką tego dania. Pizza Margherita składa się z prostych składników: cienkiego ciasta, sosu pomidorowego, mozzarelli i świeżych listków bazylii.\\n\\nW dzisiejszych czasach przygotowanie domowej Margherita pizzy jest bardzo popularne. Wiele osób decyduje się na własnoręczne przygotowanie tego dania, aby móc dostosować składniki i smaki do swoich preferencji. W kolejnych rozdziałach przedstawimy krok po k',\n",
       " 'Niezbędne składniki na pizzę Wszyscy kochamy pizzę, a jednym z najbardziej klasycznych i popularnych rodzajów jest Margherita. Aby przygotować tę pyszną i prostą wersję pizzy, potrzebujemy tylko kilku podstawowych składników. Pierwszym z nich jest oczywiście ciasto - możemy je kupić gotowe w sklepie lub przygotować własne, używając mąki, drożdży, soli, wody i oliwy. Następnie potrzebujemy sosu pomidorowego, który możemy przygotować samodzielnie z pomidorów, czosnku, oliwy i przypraw, lub zakupić gotowy w sklepie. Kolejnym niezbędnym składnikiem jest mozzarella - świeża, kremowa i pełna smaku.',\n",
       " 'Robienie pizzy Robienie pizzy to jedno z najbardziej satysfakcjonujących doświadczeń kulinarnych. Jednym z najpopularniejszych rodzajów pizzy jest Margherita, która jest znana ze swojej prostoty i wyjątkowego smaku. W tym rozdziale dowiesz się, jak przygotować autentyczną Margheritę w domowym zaciszu. Od wyboru składników po techniki pieczenia - odkryj tajniki robienia idealnej pizzy Margherita. Przygotuj się na kulinarne przygody!',\n",
       " 'Pieczenie pizzy w piekarniku Pieczenie pizzy w piekarniku jest jednym z najpopularniejszych sposobów przygotowywania pysznej Margherity. Aby rozpocząć, należy ustawić piekarnik na temperaturę 220 stopni Celsjusza i pozwolić mu się nagrzać. Następnie, przygotuj ciasto, które składa się z mąki, drożdży, soli, wody i oliwy z oliwek. Po wyrośnięciu ciasta, rozwałkuj je na okrągłą formę i umieść na blasze do pieczenia. Dodaj sos pomidorowy, świeże pomidory, mozzarellę i liście bazylii na wierzch ciasta. Piecz pizzę w nagrzanym piekarniku przez około 12-15 minut, aż skorupa będzie chrupiąca, a ser roztopiony i złocisty.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': -2, 'msg': 'token has expired or never existed'}\n"
     ]
    }
   ],
   "source": [
    "result = submit_answer(token, blog_entry)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generating titles one by one results in less consistent text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chapter_content(chapter_title):\n",
    "    prompt = f'''\n",
    "    Please in Polish, write following chapter of blog post about preparation of pizza Margherita, up to 4 sentences:\n",
    "    Title: {chapter_title}\n",
    "    '''\n",
    "\n",
    "    return chapter_title + \": \" + get_completion(prompt, model=\"gpt-3.5-turbo\", max_tokens=300, temperature=0.3)\n",
    "\n",
    "def generate_blog_entry(chapter_titles):\n",
    "    blog_entry = []\n",
    "    for title in chapter_titles:\n",
    "        chapter_content = generate_chapter_content(title)\n",
    "        print(chapter_content)\n",
    "        blog_entry.append(chapter_content)\n",
    "    return blog_entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wstęp: kilka słów na temat historii pizzy: Pizza Margherita, znana również jako królowa pizz, jest jednym z najbardziej klasycznych i popularnych rodzajów pizzy na świecie. Jej historia sięga XIX wieku, kiedy to królowa Włoch, Margherita Savoia, odwiedziła Neapol. Podczas swojej wizyty, królowa zażyczyła sobie spróbować lokalnej pizzy, co skłoniło pizzaiolo do stworzenia specjalnej kompozycji z białym serem, pomidorami i bazylią, nawiązującej do kolorów włoskiej flagi. Od tamtej pory pizza Margherita zdobyła serca wielu smakoszy na całym świecie.\n",
      "Niezbędne składniki na pizzę: Wszystko zaczyna się od odpowiednich składników, które są niezbędne do przygotowania pysznej pizzy Margherita. Na liście zakupów powinny znaleźć się: świeże pomidory, mozzarella, świeża bazylia, oliwa z oliwek, sól i pieprz oraz ciasto na pizzę. Ważne jest, aby wybrać najwyższej jakości składniki, które zapewnią autentyczny smak tej klasycznej włoskiej potrawy.\n",
      "Robienie pizzy: Rozdział 3: Pizza Margherita - klasyka włoskiej kuchni\n",
      "Pizza Margherita to jedno z najbardziej klasycznych dań włoskiej kuchni. Aby przygotować tę pyszną pizzę, potrzebujemy kilku podstawowych składników. Na początek, musimy przygotować ciasto, które składa się z mąki, wody, drożdży, soli i oliwy. Następnie, na cienko rozwałkowanym cieście, rozsmarowujemy sos pomidorowy i układamy plasterki świeżego pomidora oraz mozzarellę. Całość pieczemy w nagrzanym piekarniku, aż ciasto będzie chrupiące, a ser roztopiony i lekko zrumieniony.\n",
      "Pieczenie pizzy w piekarniku: Pieczenie pizzy w piekarniku jest prostym sposobem na przygotowanie pysznej Margherity w domu. Po rozwałkowaniu ciasta na placek, należy go umieścić na blasze wyłożonej papierem do pieczenia. Następnie, na cieście rozsmarowujemy sos pomidorowy i posypujemy startym serem mozzarella. Gotową pizzę wkładamy do nagrzanego piekarnika i pieczemy przez około 15-20 minut, aż ciasto będzie chrupiące, a ser roztopiony i lekko zrumieniony.\n",
      "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}\n"
     ]
    }
   ],
   "source": [
    "blog = generate_blog_entry(task)\n",
    "\n",
    "result = submit_answer(token, blog)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# moderation\n",
    "\n",
    "Zastosuj wiedzę na temat działania modułu do moderacji treści i rozwiąż zadanie o nazwie “moderation” z użyciem naszego API do sprawdzania rozwiązań. Zadanie polega na odebraniu tablicy zdań (4 sztuki), a następnie zwróceniu tablicy z informacją, które zdania nie przeszły moderacji. Jeśli moderacji nie przeszło pierwsze i ostatnie zdanie, to odpowiedź powinna brzmieć [1,0,0,1]. Pamiętaj, aby w polu ‘answer’ zwrócić tablicę w JSON, a nie czystego stringa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"moderation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['azjaci są głupi i brzydcy i nie powinni żyć', 'ten gość musi zginąć. Nie pozwole sobię na obrażanie mnie.', 'Sasha.Grey.s3x.p0rn.extreme-interracial.S03E12.DVDRip.mp4', 'majonez Winiary jest lepszy od Kieleckiego']\n"
     ]
    }
   ],
   "source": [
    "token = get_token(task_name)['token']\n",
    "task = get_task(token)['input']\n",
    "\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moderation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold the moderation results\n",
    "moderation_results = []\n",
    "\n",
    "# Iterate through each item in the zadanie list\n",
    "for item in task:\n",
    "    # Send the item to the Moderation endpoint\n",
    "    response = openai.Moderation.create(input=item)\n",
    "    \n",
    "    # Access the 'flagged' value from the response\n",
    "    flagged = response['results'][0]['flagged']\n",
    "    \n",
    "    # Append 1 if flagged, else 0, to the moderation_results list\n",
    "    moderation_results.append(1 if flagged else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moderation_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}\n"
     ]
    }
   ],
   "source": [
    "result = submit_answer(token, moderation_results)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helloapi\n",
    "\n",
    "Komunikacja z API odbywa się z pomocą kodu oraz formatu JSON, a każde z zadań składa się z trzech części:\n",
    "\n",
    "autoryzacji\n",
    "\n",
    "pobierania danych wejściowych (string lub tablica obiektów)\n",
    "\n",
    "odesłania odpowiedzi (właściwość answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"helloapi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 0, 'msg': 'OK', 'note': 'CORRECT'}\n"
     ]
    }
   ],
   "source": [
    "token = get_token(task_name)['token']\n",
    "cookie = get_task(token)['cookie']\n",
    "result = submit_answer(token, cookie)\n",
    "\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
